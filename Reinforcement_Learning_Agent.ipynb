{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62428539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 13:58:09.919700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense, LSTM, TimeDistributed, RepeatVector\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.layers  import  LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import Input, Dropout, Dense, LSTM, TimeDistributed, RepeatVector\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "# Multiple Inputs\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "#from tensorflow.keras.layers.convolutional import Conv2D\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.models import load_model\n",
    "import math, sys, time\n",
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import GRU, TimeDistributed, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Flatten, Dropout, Input\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "from pandas._testing import assert_frame_equal\n",
    "from pandas.testing import assert_index_equal\n",
    "assert sys.version_info >= (3, 5)\n",
    "assert sklearn.__version__ >= \"0.20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47decd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EEGP import EEGPreprocessor\n",
    "from Env_Agent import TFAccelerometerEnv\n",
    "import gym\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from scipy.signal import butter, filtfilt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a22a2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3491e686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.environments.py_environment import PyEnvironment\n",
    "from tf_agents.specs.array_spec import BoundedArraySpec\n",
    "from tf_agents.trajectories.time_step import TimeStep\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.networks import q_network\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.trajectories import time_step\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.trajectories import time_step_spec\n",
    "from tf_agents.specs import tensor_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0197e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import q_network\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae2613c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04fea186",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/charleshajjar/Documents/DataAnalyse/srcs_dir/processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e3dc9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/charleshajjar/Documents/DataAnalyse/-_-*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d2182bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relative Energy</th>\n",
       "      <th>Target</th>\n",
       "      <th>p_value_fdr</th>\n",
       "      <th>Accelerometer X</th>\n",
       "      <th>Accelerometer Y</th>\n",
       "      <th>Accelerometer Z</th>\n",
       "      <th>Gyroscope X</th>\n",
       "      <th>Gyroscope Y</th>\n",
       "      <th>Gyroscope Z</th>\n",
       "      <th>Mean Spectral Accel X</th>\n",
       "      <th>Mean Spectral Accel Y</th>\n",
       "      <th>Mean Spectral Accel Z</th>\n",
       "      <th>Mean Spectral Gyro X</th>\n",
       "      <th>Mean Spectral Gyro Y</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.367064</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025356</td>\n",
       "      <td>0.981690</td>\n",
       "      <td>-0.143450</td>\n",
       "      <td>-1.081194</td>\n",
       "      <td>-2.450127</td>\n",
       "      <td>3.117151</td>\n",
       "      <td>0.557389</td>\n",
       "      <td>0.797654</td>\n",
       "      <td>5.515205</td>\n",
       "      <td>2.113805</td>\n",
       "      <td>4.460929</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.568264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087728</td>\n",
       "      <td>0.976075</td>\n",
       "      <td>-0.169434</td>\n",
       "      <td>-0.956218</td>\n",
       "      <td>2.126057</td>\n",
       "      <td>0.956216</td>\n",
       "      <td>0.582181</td>\n",
       "      <td>0.809969</td>\n",
       "      <td>3.256564</td>\n",
       "      <td>1.057465</td>\n",
       "      <td>2.789418</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.040786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952618</td>\n",
       "      <td>0.025654</td>\n",
       "      <td>0.981709</td>\n",
       "      <td>-0.142724</td>\n",
       "      <td>-1.110840</td>\n",
       "      <td>-1.467286</td>\n",
       "      <td>2.667237</td>\n",
       "      <td>0.798439</td>\n",
       "      <td>0.898320</td>\n",
       "      <td>8.403838</td>\n",
       "      <td>3.170158</td>\n",
       "      <td>6.822606</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.035578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.952618</td>\n",
       "      <td>0.085205</td>\n",
       "      <td>0.969238</td>\n",
       "      <td>-0.169922</td>\n",
       "      <td>0.305176</td>\n",
       "      <td>2.075200</td>\n",
       "      <td>1.190190</td>\n",
       "      <td>0.346481</td>\n",
       "      <td>0.757449</td>\n",
       "      <td>1.192318</td>\n",
       "      <td>0.417153</td>\n",
       "      <td>0.806835</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.030613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952618</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.982178</td>\n",
       "      <td>-0.143066</td>\n",
       "      <td>-0.976562</td>\n",
       "      <td>-3.936770</td>\n",
       "      <td>3.784180</td>\n",
       "      <td>0.364979</td>\n",
       "      <td>0.745392</td>\n",
       "      <td>4.821071</td>\n",
       "      <td>1.858669</td>\n",
       "      <td>3.887651</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107775</th>\n",
       "      <td>18.319197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017282</td>\n",
       "      <td>0.063452</td>\n",
       "      <td>0.975521</td>\n",
       "      <td>-0.156985</td>\n",
       "      <td>-0.927404</td>\n",
       "      <td>2.262019</td>\n",
       "      <td>1.173500</td>\n",
       "      <td>0.818386</td>\n",
       "      <td>1.047708</td>\n",
       "      <td>5.093434</td>\n",
       "      <td>1.691605</td>\n",
       "      <td>4.381146</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107776</th>\n",
       "      <td>18.196864</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007870</td>\n",
       "      <td>0.097544</td>\n",
       "      <td>0.959902</td>\n",
       "      <td>-0.210347</td>\n",
       "      <td>-0.864893</td>\n",
       "      <td>2.193522</td>\n",
       "      <td>1.239030</td>\n",
       "      <td>0.814706</td>\n",
       "      <td>1.421488</td>\n",
       "      <td>4.908196</td>\n",
       "      <td>1.586571</td>\n",
       "      <td>4.343246</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107777</th>\n",
       "      <td>18.267618</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005708</td>\n",
       "      <td>0.075208</td>\n",
       "      <td>0.959926</td>\n",
       "      <td>-0.215648</td>\n",
       "      <td>-0.804538</td>\n",
       "      <td>2.102252</td>\n",
       "      <td>1.293337</td>\n",
       "      <td>0.841135</td>\n",
       "      <td>1.558894</td>\n",
       "      <td>4.965797</td>\n",
       "      <td>1.599440</td>\n",
       "      <td>4.432133</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107778</th>\n",
       "      <td>18.427590</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005758</td>\n",
       "      <td>0.019449</td>\n",
       "      <td>0.940266</td>\n",
       "      <td>-0.281695</td>\n",
       "      <td>-0.735107</td>\n",
       "      <td>1.984536</td>\n",
       "      <td>1.369888</td>\n",
       "      <td>0.908618</td>\n",
       "      <td>1.807997</td>\n",
       "      <td>5.113246</td>\n",
       "      <td>1.647190</td>\n",
       "      <td>4.620527</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107779</th>\n",
       "      <td>18.102088</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005351</td>\n",
       "      <td>0.115666</td>\n",
       "      <td>0.949394</td>\n",
       "      <td>-0.237045</td>\n",
       "      <td>-0.996489</td>\n",
       "      <td>2.193533</td>\n",
       "      <td>1.202815</td>\n",
       "      <td>0.846914</td>\n",
       "      <td>1.348586</td>\n",
       "      <td>5.296994</td>\n",
       "      <td>1.718222</td>\n",
       "      <td>4.701112</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107780 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Relative Energy  Target  p_value_fdr  Accelerometer X  \\\n",
       "0             35.367064     1.0     1.000000         0.025356   \n",
       "1             14.568264     0.0     1.000000         0.087728   \n",
       "2             28.040786     1.0     0.952618         0.025654   \n",
       "3             22.035578     0.0     0.952618         0.085205   \n",
       "4             48.030613     1.0     0.952618         0.027344   \n",
       "...                 ...     ...          ...              ...   \n",
       "107775        18.319197     1.0     0.017282         0.063452   \n",
       "107776        18.196864     1.0     0.007870         0.097544   \n",
       "107777        18.267618     1.0     0.005708         0.075208   \n",
       "107778        18.427590     1.0     0.005758         0.019449   \n",
       "107779        18.102088     1.0     0.005351         0.115666   \n",
       "\n",
       "        Accelerometer Y  Accelerometer Z  Gyroscope X  Gyroscope Y  \\\n",
       "0              0.981690        -0.143450    -1.081194    -2.450127   \n",
       "1              0.976075        -0.169434    -0.956218     2.126057   \n",
       "2              0.981709        -0.142724    -1.110840    -1.467286   \n",
       "3              0.969238        -0.169922     0.305176     2.075200   \n",
       "4              0.982178        -0.143066    -0.976562    -3.936770   \n",
       "...                 ...              ...          ...          ...   \n",
       "107775         0.975521        -0.156985    -0.927404     2.262019   \n",
       "107776         0.959902        -0.210347    -0.864893     2.193522   \n",
       "107777         0.959926        -0.215648    -0.804538     2.102252   \n",
       "107778         0.940266        -0.281695    -0.735107     1.984536   \n",
       "107779         0.949394        -0.237045    -0.996489     2.193533   \n",
       "\n",
       "        Gyroscope Z  Mean Spectral Accel X  Mean Spectral Accel Y  \\\n",
       "0          3.117151               0.557389               0.797654   \n",
       "1          0.956216               0.582181               0.809969   \n",
       "2          2.667237               0.798439               0.898320   \n",
       "3          1.190190               0.346481               0.757449   \n",
       "4          3.784180               0.364979               0.745392   \n",
       "...             ...                    ...                    ...   \n",
       "107775     1.173500               0.818386               1.047708   \n",
       "107776     1.239030               0.814706               1.421488   \n",
       "107777     1.293337               0.841135               1.558894   \n",
       "107778     1.369888               0.908618               1.807997   \n",
       "107779     1.202815               0.846914               1.348586   \n",
       "\n",
       "        Mean Spectral Accel Z  Mean Spectral Gyro X  Mean Spectral Gyro Y  \\\n",
       "0                    5.515205              2.113805              4.460929   \n",
       "1                    3.256564              1.057465              2.789418   \n",
       "2                    8.403838              3.170158              6.822606   \n",
       "3                    1.192318              0.417153              0.806835   \n",
       "4                    4.821071              1.858669              3.887651   \n",
       "...                       ...                   ...                   ...   \n",
       "107775               5.093434              1.691605              4.381146   \n",
       "107776               4.908196              1.586571              4.343246   \n",
       "107777               4.965797              1.599440              4.432133   \n",
       "107778               5.113246              1.647190              4.620527   \n",
       "107779               5.296994              1.718222              4.701112   \n",
       "\n",
       "        Label  \n",
       "0           4  \n",
       "1           2  \n",
       "2           4  \n",
       "3           2  \n",
       "4           4  \n",
       "...       ...  \n",
       "107775      5  \n",
       "107776      5  \n",
       "107777      5  \n",
       "107778      5  \n",
       "107779      5  \n",
       "\n",
       "[107780 rows x 15 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8cd6516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relative Energy</th>\n",
       "      <th>Target</th>\n",
       "      <th>p_value_fdr</th>\n",
       "      <th>Accelerometer X</th>\n",
       "      <th>Accelerometer Y</th>\n",
       "      <th>Accelerometer Z</th>\n",
       "      <th>Gyroscope X</th>\n",
       "      <th>Gyroscope Y</th>\n",
       "      <th>Gyroscope Z</th>\n",
       "      <th>Mean Spectral Accel X</th>\n",
       "      <th>Mean Spectral Accel Y</th>\n",
       "      <th>Mean Spectral Accel Z</th>\n",
       "      <th>Mean Spectral Gyro X</th>\n",
       "      <th>Mean Spectral Gyro Y</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.367064</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025356</td>\n",
       "      <td>0.981690</td>\n",
       "      <td>-0.143450</td>\n",
       "      <td>-1.081194</td>\n",
       "      <td>-2.450127</td>\n",
       "      <td>3.117151</td>\n",
       "      <td>0.557389</td>\n",
       "      <td>0.797654</td>\n",
       "      <td>5.515205</td>\n",
       "      <td>2.113805</td>\n",
       "      <td>4.460929</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.568264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087728</td>\n",
       "      <td>0.976075</td>\n",
       "      <td>-0.169434</td>\n",
       "      <td>-0.956218</td>\n",
       "      <td>2.126057</td>\n",
       "      <td>0.956216</td>\n",
       "      <td>0.582181</td>\n",
       "      <td>0.809969</td>\n",
       "      <td>3.256564</td>\n",
       "      <td>1.057465</td>\n",
       "      <td>2.789418</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.040786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952618</td>\n",
       "      <td>0.025654</td>\n",
       "      <td>0.981709</td>\n",
       "      <td>-0.142724</td>\n",
       "      <td>-1.110840</td>\n",
       "      <td>-1.467286</td>\n",
       "      <td>2.667237</td>\n",
       "      <td>0.798439</td>\n",
       "      <td>0.898320</td>\n",
       "      <td>8.403838</td>\n",
       "      <td>3.170158</td>\n",
       "      <td>6.822606</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.035578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.952618</td>\n",
       "      <td>0.085205</td>\n",
       "      <td>0.969238</td>\n",
       "      <td>-0.169922</td>\n",
       "      <td>0.305176</td>\n",
       "      <td>2.075200</td>\n",
       "      <td>1.190190</td>\n",
       "      <td>0.346481</td>\n",
       "      <td>0.757449</td>\n",
       "      <td>1.192318</td>\n",
       "      <td>0.417153</td>\n",
       "      <td>0.806835</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.030613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952618</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.982178</td>\n",
       "      <td>-0.143066</td>\n",
       "      <td>-0.976562</td>\n",
       "      <td>-3.936770</td>\n",
       "      <td>3.784180</td>\n",
       "      <td>0.364979</td>\n",
       "      <td>0.745392</td>\n",
       "      <td>4.821071</td>\n",
       "      <td>1.858669</td>\n",
       "      <td>3.887651</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107775</th>\n",
       "      <td>18.319197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017282</td>\n",
       "      <td>0.063452</td>\n",
       "      <td>0.975521</td>\n",
       "      <td>-0.156985</td>\n",
       "      <td>-0.927404</td>\n",
       "      <td>2.262019</td>\n",
       "      <td>1.173500</td>\n",
       "      <td>0.818386</td>\n",
       "      <td>1.047708</td>\n",
       "      <td>5.093434</td>\n",
       "      <td>1.691605</td>\n",
       "      <td>4.381146</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107776</th>\n",
       "      <td>18.196864</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007870</td>\n",
       "      <td>0.097544</td>\n",
       "      <td>0.959902</td>\n",
       "      <td>-0.210347</td>\n",
       "      <td>-0.864893</td>\n",
       "      <td>2.193522</td>\n",
       "      <td>1.239030</td>\n",
       "      <td>0.814706</td>\n",
       "      <td>1.421488</td>\n",
       "      <td>4.908196</td>\n",
       "      <td>1.586571</td>\n",
       "      <td>4.343246</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107777</th>\n",
       "      <td>18.267618</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005708</td>\n",
       "      <td>0.075208</td>\n",
       "      <td>0.959926</td>\n",
       "      <td>-0.215648</td>\n",
       "      <td>-0.804538</td>\n",
       "      <td>2.102252</td>\n",
       "      <td>1.293337</td>\n",
       "      <td>0.841135</td>\n",
       "      <td>1.558894</td>\n",
       "      <td>4.965797</td>\n",
       "      <td>1.599440</td>\n",
       "      <td>4.432133</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107778</th>\n",
       "      <td>18.427590</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005758</td>\n",
       "      <td>0.019449</td>\n",
       "      <td>0.940266</td>\n",
       "      <td>-0.281695</td>\n",
       "      <td>-0.735107</td>\n",
       "      <td>1.984536</td>\n",
       "      <td>1.369888</td>\n",
       "      <td>0.908618</td>\n",
       "      <td>1.807997</td>\n",
       "      <td>5.113246</td>\n",
       "      <td>1.647190</td>\n",
       "      <td>4.620527</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107779</th>\n",
       "      <td>18.102088</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005351</td>\n",
       "      <td>0.115666</td>\n",
       "      <td>0.949394</td>\n",
       "      <td>-0.237045</td>\n",
       "      <td>-0.996489</td>\n",
       "      <td>2.193533</td>\n",
       "      <td>1.202815</td>\n",
       "      <td>0.846914</td>\n",
       "      <td>1.348586</td>\n",
       "      <td>5.296994</td>\n",
       "      <td>1.718222</td>\n",
       "      <td>4.701112</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107780 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Relative Energy  Target  p_value_fdr  Accelerometer X  \\\n",
       "0             35.367064     1.0     1.000000         0.025356   \n",
       "1             14.568264     0.0     1.000000         0.087728   \n",
       "2             28.040786     1.0     0.952618         0.025654   \n",
       "3             22.035578     0.0     0.952618         0.085205   \n",
       "4             48.030613     1.0     0.952618         0.027344   \n",
       "...                 ...     ...          ...              ...   \n",
       "107775        18.319197     1.0     0.017282         0.063452   \n",
       "107776        18.196864     1.0     0.007870         0.097544   \n",
       "107777        18.267618     1.0     0.005708         0.075208   \n",
       "107778        18.427590     1.0     0.005758         0.019449   \n",
       "107779        18.102088     1.0     0.005351         0.115666   \n",
       "\n",
       "        Accelerometer Y  Accelerometer Z  Gyroscope X  Gyroscope Y  \\\n",
       "0              0.981690        -0.143450    -1.081194    -2.450127   \n",
       "1              0.976075        -0.169434    -0.956218     2.126057   \n",
       "2              0.981709        -0.142724    -1.110840    -1.467286   \n",
       "3              0.969238        -0.169922     0.305176     2.075200   \n",
       "4              0.982178        -0.143066    -0.976562    -3.936770   \n",
       "...                 ...              ...          ...          ...   \n",
       "107775         0.975521        -0.156985    -0.927404     2.262019   \n",
       "107776         0.959902        -0.210347    -0.864893     2.193522   \n",
       "107777         0.959926        -0.215648    -0.804538     2.102252   \n",
       "107778         0.940266        -0.281695    -0.735107     1.984536   \n",
       "107779         0.949394        -0.237045    -0.996489     2.193533   \n",
       "\n",
       "        Gyroscope Z  Mean Spectral Accel X  Mean Spectral Accel Y  \\\n",
       "0          3.117151               0.557389               0.797654   \n",
       "1          0.956216               0.582181               0.809969   \n",
       "2          2.667237               0.798439               0.898320   \n",
       "3          1.190190               0.346481               0.757449   \n",
       "4          3.784180               0.364979               0.745392   \n",
       "...             ...                    ...                    ...   \n",
       "107775     1.173500               0.818386               1.047708   \n",
       "107776     1.239030               0.814706               1.421488   \n",
       "107777     1.293337               0.841135               1.558894   \n",
       "107778     1.369888               0.908618               1.807997   \n",
       "107779     1.202815               0.846914               1.348586   \n",
       "\n",
       "        Mean Spectral Accel Z  Mean Spectral Gyro X  Mean Spectral Gyro Y  \\\n",
       "0                    5.515205              2.113805              4.460929   \n",
       "1                    3.256564              1.057465              2.789418   \n",
       "2                    8.403838              3.170158              6.822606   \n",
       "3                    1.192318              0.417153              0.806835   \n",
       "4                    4.821071              1.858669              3.887651   \n",
       "...                       ...                   ...                   ...   \n",
       "107775               5.093434              1.691605              4.381146   \n",
       "107776               4.908196              1.586571              4.343246   \n",
       "107777               4.965797              1.599440              4.432133   \n",
       "107778               5.113246              1.647190              4.620527   \n",
       "107779               5.296994              1.718222              4.701112   \n",
       "\n",
       "        Label  \n",
       "0           4  \n",
       "1           2  \n",
       "2           4  \n",
       "3           2  \n",
       "4           4  \n",
       "...       ...  \n",
       "107775      5  \n",
       "107776      5  \n",
       "107777      5  \n",
       "107778      5  \n",
       "107779      5  \n",
       "\n",
       "[107780 rows x 15 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a36738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb80a5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relative Energy</th>\n",
       "      <th>Target</th>\n",
       "      <th>p_value_fdr</th>\n",
       "      <th>Accelerometer X</th>\n",
       "      <th>Accelerometer Y</th>\n",
       "      <th>Accelerometer Z</th>\n",
       "      <th>Gyroscope X</th>\n",
       "      <th>Gyroscope Y</th>\n",
       "      <th>Gyroscope Z</th>\n",
       "      <th>Mean Spectral Accel X</th>\n",
       "      <th>Mean Spectral Accel Y</th>\n",
       "      <th>Mean Spectral Accel Z</th>\n",
       "      <th>Mean Spectral Gyro X</th>\n",
       "      <th>Mean Spectral Gyro Y</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96314</th>\n",
       "      <td>41.707799</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020702</td>\n",
       "      <td>0.110987</td>\n",
       "      <td>0.908690</td>\n",
       "      <td>-0.326694</td>\n",
       "      <td>-1.007080</td>\n",
       "      <td>3.077629</td>\n",
       "      <td>2.151387</td>\n",
       "      <td>0.441615</td>\n",
       "      <td>0.507709</td>\n",
       "      <td>2.508990</td>\n",
       "      <td>0.843990</td>\n",
       "      <td>2.112585</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97059</th>\n",
       "      <td>22.675154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006367</td>\n",
       "      <td>0.118748</td>\n",
       "      <td>0.950712</td>\n",
       "      <td>-0.245830</td>\n",
       "      <td>-0.959858</td>\n",
       "      <td>2.276996</td>\n",
       "      <td>1.546830</td>\n",
       "      <td>0.739879</td>\n",
       "      <td>0.915729</td>\n",
       "      <td>3.943563</td>\n",
       "      <td>1.309612</td>\n",
       "      <td>3.305086</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61911</th>\n",
       "      <td>71.949614</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028959</td>\n",
       "      <td>0.094461</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>-0.234533</td>\n",
       "      <td>0.027140</td>\n",
       "      <td>1.883276</td>\n",
       "      <td>3.504208</td>\n",
       "      <td>0.477057</td>\n",
       "      <td>0.868529</td>\n",
       "      <td>1.136679</td>\n",
       "      <td>0.383200</td>\n",
       "      <td>0.803338</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>7.021346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.019830</td>\n",
       "      <td>0.056071</td>\n",
       "      <td>0.979655</td>\n",
       "      <td>-0.141602</td>\n",
       "      <td>-1.159670</td>\n",
       "      <td>1.434327</td>\n",
       "      <td>0.752767</td>\n",
       "      <td>0.548900</td>\n",
       "      <td>0.606078</td>\n",
       "      <td>2.647694</td>\n",
       "      <td>0.846745</td>\n",
       "      <td>2.248161</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107245</th>\n",
       "      <td>25.742572</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.012532</td>\n",
       "      <td>0.101903</td>\n",
       "      <td>0.945817</td>\n",
       "      <td>-0.251338</td>\n",
       "      <td>-1.444099</td>\n",
       "      <td>2.722067</td>\n",
       "      <td>1.560627</td>\n",
       "      <td>0.737307</td>\n",
       "      <td>0.692701</td>\n",
       "      <td>4.506922</td>\n",
       "      <td>1.483472</td>\n",
       "      <td>3.942547</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27364</th>\n",
       "      <td>20.539506</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007955</td>\n",
       "      <td>0.098006</td>\n",
       "      <td>0.920049</td>\n",
       "      <td>-0.325452</td>\n",
       "      <td>-1.424885</td>\n",
       "      <td>2.436688</td>\n",
       "      <td>1.439051</td>\n",
       "      <td>0.429668</td>\n",
       "      <td>0.415062</td>\n",
       "      <td>2.480503</td>\n",
       "      <td>0.816549</td>\n",
       "      <td>2.126520</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84145</th>\n",
       "      <td>20.542296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006321</td>\n",
       "      <td>0.090904</td>\n",
       "      <td>0.951388</td>\n",
       "      <td>-0.253496</td>\n",
       "      <td>-1.379833</td>\n",
       "      <td>0.841481</td>\n",
       "      <td>-0.027294</td>\n",
       "      <td>0.918800</td>\n",
       "      <td>1.226345</td>\n",
       "      <td>6.973152</td>\n",
       "      <td>2.286131</td>\n",
       "      <td>6.287924</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22205</th>\n",
       "      <td>24.789963</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021272</td>\n",
       "      <td>0.101742</td>\n",
       "      <td>0.913075</td>\n",
       "      <td>-0.324510</td>\n",
       "      <td>-0.809070</td>\n",
       "      <td>2.442821</td>\n",
       "      <td>1.591408</td>\n",
       "      <td>0.410200</td>\n",
       "      <td>0.558037</td>\n",
       "      <td>2.060018</td>\n",
       "      <td>0.689943</td>\n",
       "      <td>1.686231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70555</th>\n",
       "      <td>28.025340</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>0.142278</td>\n",
       "      <td>0.932065</td>\n",
       "      <td>-0.279443</td>\n",
       "      <td>-0.909751</td>\n",
       "      <td>2.691491</td>\n",
       "      <td>1.580733</td>\n",
       "      <td>0.849726</td>\n",
       "      <td>1.217284</td>\n",
       "      <td>5.515933</td>\n",
       "      <td>1.840525</td>\n",
       "      <td>4.742219</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4190</th>\n",
       "      <td>3.360923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013735</td>\n",
       "      <td>0.077881</td>\n",
       "      <td>0.904199</td>\n",
       "      <td>-0.373633</td>\n",
       "      <td>-1.672366</td>\n",
       "      <td>0.445557</td>\n",
       "      <td>0.012207</td>\n",
       "      <td>0.637663</td>\n",
       "      <td>0.842951</td>\n",
       "      <td>3.071177</td>\n",
       "      <td>0.926376</td>\n",
       "      <td>2.754706</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107780 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Relative Energy  Target  p_value_fdr  Accelerometer X  \\\n",
       "96314         41.707799     1.0     0.020702         0.110987   \n",
       "97059         22.675154     1.0     0.006367         0.118748   \n",
       "61911         71.949614     1.0     0.028959         0.094461   \n",
       "314            7.021346     1.0     0.019830         0.056071   \n",
       "107245        25.742572     1.0     0.012532         0.101903   \n",
       "...                 ...     ...          ...              ...   \n",
       "27364         20.539506     1.0     0.007955         0.098006   \n",
       "84145         20.542296     1.0     0.006321         0.090904   \n",
       "22205         24.789963     1.0     0.021272         0.101742   \n",
       "70555         28.025340     1.0     0.012687         0.142278   \n",
       "4190           3.360923     0.0     0.013735         0.077881   \n",
       "\n",
       "        Accelerometer Y  Accelerometer Z  Gyroscope X  Gyroscope Y  \\\n",
       "96314          0.908690        -0.326694    -1.007080     3.077629   \n",
       "97059          0.950712        -0.245830    -0.959858     2.276996   \n",
       "61911          0.956667        -0.234533     0.027140     1.883276   \n",
       "314            0.979655        -0.141602    -1.159670     1.434327   \n",
       "107245         0.945817        -0.251338    -1.444099     2.722067   \n",
       "...                 ...              ...          ...          ...   \n",
       "27364          0.920049        -0.325452    -1.424885     2.436688   \n",
       "84145          0.951388        -0.253496    -1.379833     0.841481   \n",
       "22205          0.913075        -0.324510    -0.809070     2.442821   \n",
       "70555          0.932065        -0.279443    -0.909751     2.691491   \n",
       "4190           0.904199        -0.373633    -1.672366     0.445557   \n",
       "\n",
       "        Gyroscope Z  Mean Spectral Accel X  Mean Spectral Accel Y  \\\n",
       "96314      2.151387               0.441615               0.507709   \n",
       "97059      1.546830               0.739879               0.915729   \n",
       "61911      3.504208               0.477057               0.868529   \n",
       "314        0.752767               0.548900               0.606078   \n",
       "107245     1.560627               0.737307               0.692701   \n",
       "...             ...                    ...                    ...   \n",
       "27364      1.439051               0.429668               0.415062   \n",
       "84145     -0.027294               0.918800               1.226345   \n",
       "22205      1.591408               0.410200               0.558037   \n",
       "70555      1.580733               0.849726               1.217284   \n",
       "4190       0.012207               0.637663               0.842951   \n",
       "\n",
       "        Mean Spectral Accel Z  Mean Spectral Gyro X  Mean Spectral Gyro Y  \\\n",
       "96314                2.508990              0.843990              2.112585   \n",
       "97059                3.943563              1.309612              3.305086   \n",
       "61911                1.136679              0.383200              0.803338   \n",
       "314                  2.647694              0.846745              2.248161   \n",
       "107245               4.506922              1.483472              3.942547   \n",
       "...                       ...                   ...                   ...   \n",
       "27364                2.480503              0.816549              2.126520   \n",
       "84145                6.973152              2.286131              6.287924   \n",
       "22205                2.060018              0.689943              1.686231   \n",
       "70555                5.515933              1.840525              4.742219   \n",
       "4190                 3.071177              0.926376              2.754706   \n",
       "\n",
       "        Label  \n",
       "96314       5  \n",
       "97059       5  \n",
       "61911       3  \n",
       "314         2  \n",
       "107245      5  \n",
       "...       ...  \n",
       "27364       0  \n",
       "84145       4  \n",
       "22205       0  \n",
       "70555       3  \n",
       "4190        2  \n",
       "\n",
       "[107780 rows x 15 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2b868a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"Target\"] = df[\"Target\"].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1969bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and preprocess the data\n",
    "data = df\n",
    "#data = data.drop(columns=[\"Direction\"])\n",
    "#data = data.to_numpy(dtype=np.float32)\n",
    "#df = df[['Relative Energy', 'Target', 'p_value_fdr',\n",
    "       #'Accelerometer X', 'Accelerometer Y', 'Accelerometer Z', 'Gyroscope X',\n",
    "       #'Gyroscope Y', 'Gyroscope Z', 'Mean Spectral Accel X',\n",
    "       #'Mean Spectral Accel Y', 'Mean Spectral Accel Z',\n",
    "       #'Mean Spectral Gyro X', 'Mean Spectral Gyro Y']]\n",
    "#target_col = data[\"Label\"]\n",
    "# Séparation en données d'entraînement et de validation\n",
    "#train_df, test_df, train_col, test_col = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Step 2: Create the training and testing datasets\n",
    "#train_df = data[:len(data)//2]\n",
    "#test_df = data[len(data)//2:]\n",
    "\n",
    "# Step 3: Shuffle the training data\n",
    "#np.random.shuffle(train_data)\n",
    "\n",
    "# Step 4: Create the TensorFlow environment\n",
    "#train_env = tf_py_environment.TFPyEnvironment(TFAccelerometerEnv(train_df))\n",
    "#test_env = tf_py_environment.TFPyEnvironment(TFAccelerometerEnv(test_df))\n",
    "#actions = 6\n",
    "#train_env = TFAccelerometerEnv(df[:len(df)//2], target_col, actions)\n",
    "#test_env = TFAccelerometerEnv(df[len(df)//2:], target_col, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46e42cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_env = tf_py_environment.TFPyEnvironment(TFAccelerometerEnv(train_df, train_col))\n",
    "#test_env = tf_py_environment.TFPyEnvironment(TFAccelerometerEnv(test_df, test_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43d23b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X = data.drop(['Label'], axis=1)\n",
    "y = data['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "num_classes = len(np.unique(y))\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5c9a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data[:len(data)//2]\n",
    "test_df = data[len(data)//2:]\n",
    "\n",
    "# Step 3: Shuffle the training data\n",
    "#np.random.shuffle(train_data)\n",
    "number_of_classes = df['Label'].nunique()\n",
    "# Step 4: Create the TensorFlow environment\n",
    "#train_env = tf_py_environment.TFPyEnvironment(TFAccelerometerEnv(train_df))\n",
    "#test_env = tf_py_environment.TFPyEnvironment(TFAccelerometerEnv(test_df))\n",
    "train_env = tf_py_environment.TFPyEnvironment(TFAccelerometerEnv(train_df, number_of_classes))\n",
    "test_env = tf_py_environment.TFPyEnvironment(TFAccelerometerEnv(test_df, number_of_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9591fce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Create the Q network\n",
    "fc_layer_params = (100,)\n",
    "q_net = q_network.QNetwork(\n",
    "    train_env.observation_spec(),\n",
    "    train_env.action_spec(),\n",
    "    fc_layer_params=fc_layer_params,\n",
    "    activation_fn=tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67d7d4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 14:00:28.320538: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Create the agent\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.001)\n",
    "train_step_counter = tf.Variable(0)\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=tf.losses.CategoricalCrossentropy(),\n",
    "    train_step_counter=train_step_counter)\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e271f6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Create the replay buffer\n",
    "replay_buffer_capacity = 100000\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "880bc130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Create the data collection driver\n",
    "initial_collect_steps = 1000\n",
    "collect_steps_per_iteration = 1\n",
    "num_iterations = 200000\n",
    "collect_driver = dynamic_step_driver.DynamicStepDriver(\n",
    "    train_env,\n",
    "    agent.collect_policy,\n",
    "    observers=[replay_buffer.add_batch],\n",
    "    num_steps=collect_steps_per_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f63706ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/charleshajjar/NeuralStar/lib/python3.9/site-packages/tf_agents/replay_buffers/tf_uniform_replay_buffer.py:342: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.counter(...)` instead.\n",
      "WARNING:tensorflow:From /Users/charleshajjar/NeuralStar/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n",
      "WARNING:tensorflow:From /Users/charleshajjar/NeuralStar/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Collect initial data\n",
    "for _ in range(initial_collect_steps):\n",
    "    collect_driver.run()\n",
    "\n",
    "# Step 10: Create the dataset\n",
    "batch_size = 64\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=8, \n",
    "    sample_batch_size=batch_size, \n",
    "    num_steps=2).prefetch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7d52e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Create the iterator\n",
    "iterator = iter(dataset)\n",
    "# Step 12: Train the agent\n",
    "train_step_counter = tf.Variable(0)\n",
    "@tf.function\n",
    "def train_agent(agent, iterator):\n",
    "    experience, _ = next(iterator)\n",
    "    train_step_counter.assign_add(1)\n",
    "    loss_info = agent.train(experience)\n",
    "    return loss_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d5733b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch: 0, Loss: 206.95997619628906\n",
      "Epoch: 100, Loss: 206.97250366210938\n",
      "Epoch: 200, Loss: 206.9677276611328\n",
      "Epoch: 300, Loss: 207.26687622070312\n",
      "Epoch: 400, Loss: 206.79193115234375\n",
      "Epoch: 500, Loss: 206.69412231445312\n",
      "Epoch: 600, Loss: 206.68368530273438\n",
      "Epoch: 700, Loss: 206.70578002929688\n",
      "Epoch: 800, Loss: 206.64608764648438\n",
      "Epoch: 900, Loss: 206.63803100585938\n",
      "Epoch: 1000, Loss: 206.65054321289062\n",
      "Epoch: 1100, Loss: 206.65216064453125\n",
      "Epoch: 1200, Loss: 206.59165954589844\n",
      "Epoch: 1300, Loss: 206.59921264648438\n",
      "Epoch: 1400, Loss: 206.58409118652344\n",
      "Epoch: 1500, Loss: 206.58929443359375\n",
      "Epoch: 1600, Loss: 206.56961059570312\n",
      "Epoch: 1700, Loss: 206.99725341796875\n",
      "Epoch: 1800, Loss: 206.047607421875\n",
      "Epoch: 1900, Loss: 205.81600952148438\n",
      "Epoch: 2000, Loss: 205.8162078857422\n",
      "Epoch: 2100, Loss: 205.820068359375\n",
      "Epoch: 2200, Loss: 205.83843994140625\n",
      "Epoch: 2300, Loss: 206.0316925048828\n",
      "Epoch: 2400, Loss: 205.60882568359375\n",
      "Epoch: 2500, Loss: 205.62208557128906\n",
      "Epoch: 2600, Loss: 205.68121337890625\n",
      "Epoch: 2700, Loss: 205.62802124023438\n",
      "Epoch: 2800, Loss: 205.55105590820312\n",
      "Epoch: 2900, Loss: 205.73016357421875\n",
      "Epoch: 3000, Loss: 205.4486541748047\n",
      "Epoch: 3100, Loss: 206.2164306640625\n",
      "Epoch: 3200, Loss: 204.75726318359375\n",
      "Epoch: 3300, Loss: 204.58926391601562\n",
      "Epoch: 3400, Loss: 204.58558654785156\n",
      "Epoch: 3500, Loss: 204.57949829101562\n",
      "Epoch: 3600, Loss: 204.61341857910156\n",
      "Epoch: 3700, Loss: 204.63536071777344\n",
      "Epoch: 3800, Loss: 204.690673828125\n",
      "Epoch: 3900, Loss: 204.52838134765625\n",
      "Epoch: 4000, Loss: 204.552490234375\n",
      "Epoch: 4100, Loss: 204.42518615722656\n",
      "Epoch: 4200, Loss: 204.503662109375\n",
      "Epoch: 4300, Loss: 204.37338256835938\n",
      "Epoch: 4400, Loss: 204.33824157714844\n",
      "Epoch: 4500, Loss: 204.3320770263672\n",
      "Epoch: 4600, Loss: 204.4742431640625\n",
      "Epoch: 4700, Loss: 204.52301025390625\n",
      "Epoch: 4800, Loss: 204.08181762695312\n",
      "Epoch: 4900, Loss: 204.17652893066406\n",
      "Epoch: 5000, Loss: 204.02313232421875\n",
      "Epoch: 5100, Loss: 204.14505004882812\n",
      "Epoch: 5200, Loss: 204.1732177734375\n",
      "Epoch: 5300, Loss: 204.34095764160156\n",
      "Epoch: 5400, Loss: 203.37445068359375\n",
      "Epoch: 5500, Loss: 202.79159545898438\n",
      "Epoch: 5600, Loss: 202.6904296875\n",
      "Epoch: 5700, Loss: 202.66693115234375\n",
      "Epoch: 5800, Loss: 202.6942901611328\n",
      "Epoch: 5900, Loss: 202.69363403320312\n",
      "Epoch: 6000, Loss: 202.66354370117188\n",
      "Epoch: 6100, Loss: 202.75238037109375\n",
      "Epoch: 6200, Loss: 202.67498779296875\n",
      "Epoch: 6300, Loss: 202.7181396484375\n",
      "Epoch: 6400, Loss: 202.68753051757812\n",
      "Epoch: 6500, Loss: 202.65167236328125\n",
      "Epoch: 6600, Loss: 202.85009765625\n",
      "Epoch: 6700, Loss: 202.6757354736328\n",
      "Epoch: 6800, Loss: 202.66683959960938\n",
      "Epoch: 6900, Loss: 202.5877685546875\n",
      "Epoch: 7000, Loss: 202.30508422851562\n",
      "Epoch: 7100, Loss: 201.875732421875\n",
      "Epoch: 7200, Loss: 201.9097900390625\n",
      "Epoch: 7300, Loss: 201.8719940185547\n",
      "Epoch: 7400, Loss: 201.8690948486328\n",
      "Epoch: 7500, Loss: 202.01754760742188\n",
      "Epoch: 7600, Loss: 201.82632446289062\n",
      "Epoch: 7700, Loss: 201.84246826171875\n",
      "Epoch: 7800, Loss: 202.00772094726562\n",
      "Epoch: 7900, Loss: 202.03143310546875\n",
      "Epoch: 8000, Loss: 201.77749633789062\n",
      "Epoch: 8100, Loss: 202.31924438476562\n",
      "Epoch: 8200, Loss: 200.98455810546875\n",
      "Epoch: 8300, Loss: 200.78465270996094\n",
      "Epoch: 8400, Loss: 200.746826171875\n",
      "Epoch: 8500, Loss: 200.73269653320312\n",
      "Epoch: 8600, Loss: 200.73829650878906\n",
      "Epoch: 8700, Loss: 200.7313995361328\n",
      "Epoch: 8800, Loss: 200.73397827148438\n",
      "Epoch: 8900, Loss: 200.7604522705078\n",
      "Epoch: 9000, Loss: 200.73794555664062\n",
      "Epoch: 9100, Loss: 200.765869140625\n",
      "Epoch: 9200, Loss: 200.72177124023438\n",
      "Epoch: 9300, Loss: 200.73646545410156\n",
      "Epoch: 9400, Loss: 200.93626403808594\n",
      "Epoch: 9500, Loss: 200.6907958984375\n",
      "Epoch: 9600, Loss: 200.5933837890625\n",
      "Epoch: 9700, Loss: 200.58523559570312\n",
      "Epoch: 9800, Loss: 200.6551513671875\n",
      "Epoch: 9900, Loss: 200.60879516601562\n",
      "Epoch: 10000, Loss: 201.66012573242188\n",
      "Epoch: 10100, Loss: 199.58676147460938\n",
      "Epoch: 10200, Loss: 199.50405883789062\n",
      "Epoch: 10300, Loss: 199.50924682617188\n",
      "Epoch: 10400, Loss: 199.50680541992188\n",
      "Epoch: 10500, Loss: 199.52273559570312\n",
      "Epoch: 10600, Loss: 199.52569580078125\n",
      "Epoch: 10700, Loss: 199.52809143066406\n",
      "Epoch: 10800, Loss: 199.51260375976562\n",
      "Epoch: 10900, Loss: 199.51910400390625\n",
      "Epoch: 11000, Loss: 199.51193237304688\n",
      "Epoch: 11100, Loss: 199.58853149414062\n",
      "Epoch: 11200, Loss: 199.39300537109375\n",
      "Epoch: 11300, Loss: 199.34219360351562\n",
      "Epoch: 11400, Loss: 199.41725158691406\n",
      "Epoch: 11500, Loss: 199.27590942382812\n",
      "Epoch: 11600, Loss: 199.2756805419922\n",
      "Epoch: 11700, Loss: 199.24884033203125\n",
      "Epoch: 11800, Loss: 198.8902587890625\n",
      "Epoch: 11900, Loss: 198.6290740966797\n",
      "Epoch: 12000, Loss: 198.5946044921875\n",
      "Epoch: 12100, Loss: 198.53829956054688\n",
      "Epoch: 12200, Loss: 198.55300903320312\n",
      "Epoch: 12300, Loss: 198.5574951171875\n",
      "Epoch: 12400, Loss: 198.58169555664062\n",
      "Epoch: 12500, Loss: 198.55982971191406\n",
      "Epoch: 12600, Loss: 198.5253448486328\n",
      "Epoch: 12700, Loss: 198.50650024414062\n",
      "Epoch: 12800, Loss: 198.50970458984375\n",
      "Epoch: 12900, Loss: 198.58566284179688\n",
      "Epoch: 13000, Loss: 198.57247924804688\n",
      "Epoch: 13100, Loss: 198.60037231445312\n",
      "Epoch: 13200, Loss: 198.48104858398438\n",
      "Epoch: 13300, Loss: 198.74832153320312\n",
      "Epoch: 13400, Loss: 197.67587280273438\n",
      "Epoch: 13500, Loss: 197.63206481933594\n",
      "Epoch: 13600, Loss: 197.74632263183594\n",
      "Epoch: 13700, Loss: 197.61178588867188\n",
      "Epoch: 13800, Loss: 197.61636352539062\n",
      "Epoch: 13900, Loss: 197.63861083984375\n",
      "Epoch: 14000, Loss: 197.69467163085938\n",
      "Epoch: 14100, Loss: 197.7476806640625\n",
      "Epoch: 14200, Loss: 197.4683380126953\n",
      "Epoch: 14300, Loss: 197.29449462890625\n",
      "Epoch: 14400, Loss: 197.229736328125\n",
      "Epoch: 14500, Loss: 197.24844360351562\n",
      "Epoch: 14600, Loss: 197.2708740234375\n",
      "Epoch: 14700, Loss: 197.272705078125\n",
      "Epoch: 14800, Loss: 197.25698852539062\n",
      "Epoch: 14900, Loss: 197.21937561035156\n",
      "Epoch: 15000, Loss: 197.27432250976562\n",
      "Epoch: 15100, Loss: 197.41262817382812\n",
      "Epoch: 15200, Loss: 197.3184051513672\n",
      "Epoch: 15300, Loss: 197.06390380859375\n",
      "Epoch: 15400, Loss: 196.4693603515625\n",
      "Epoch: 15500, Loss: 196.4215087890625\n",
      "Epoch: 15600, Loss: 196.42832946777344\n",
      "Epoch: 15700, Loss: 196.4620361328125\n",
      "Epoch: 15800, Loss: 196.4190673828125\n",
      "Epoch: 15900, Loss: 196.4755401611328\n",
      "Epoch: 16000, Loss: 196.47946166992188\n",
      "Epoch: 16100, Loss: 196.42701721191406\n",
      "Epoch: 16200, Loss: 196.47171020507812\n",
      "Epoch: 16300, Loss: 196.6226806640625\n",
      "Epoch: 16400, Loss: 196.3006591796875\n",
      "Epoch: 16500, Loss: 196.49229431152344\n",
      "Epoch: 16600, Loss: 196.0970001220703\n",
      "Epoch: 16700, Loss: 195.9756622314453\n",
      "Epoch: 16800, Loss: 195.98757934570312\n",
      "Epoch: 16900, Loss: 196.02691650390625\n",
      "Epoch: 17000, Loss: 195.90383911132812\n",
      "Epoch: 17100, Loss: 195.91433715820312\n",
      "Epoch: 17200, Loss: 196.492919921875\n",
      "Epoch: 17300, Loss: 195.41140747070312\n",
      "Epoch: 17400, Loss: 195.27682495117188\n",
      "Epoch: 17500, Loss: 194.9505615234375\n",
      "Epoch: 17600, Loss: 194.9208984375\n",
      "Epoch: 17700, Loss: 194.9302520751953\n",
      "Epoch: 17800, Loss: 194.92320251464844\n",
      "Epoch: 17900, Loss: 194.91757202148438\n",
      "Epoch: 18000, Loss: 194.92015075683594\n",
      "Epoch: 18100, Loss: 194.92404174804688\n",
      "Epoch: 18200, Loss: 194.923583984375\n",
      "Epoch: 18300, Loss: 194.92620849609375\n",
      "Epoch: 18400, Loss: 194.97970581054688\n",
      "Epoch: 18500, Loss: 194.988525390625\n",
      "Epoch: 18600, Loss: 195.18963623046875\n",
      "Epoch: 18700, Loss: 194.76251220703125\n",
      "Epoch: 18800, Loss: 194.82177734375\n",
      "Epoch: 18900, Loss: 194.32525634765625\n",
      "Epoch: 19000, Loss: 194.33042907714844\n",
      "Epoch: 19100, Loss: 194.32138061523438\n",
      "Epoch: 19200, Loss: 194.31494140625\n",
      "Epoch: 19300, Loss: 194.35350036621094\n",
      "Epoch: 19400, Loss: 194.3327178955078\n",
      "Epoch: 19500, Loss: 194.3194122314453\n",
      "Epoch: 19600, Loss: 194.3615264892578\n",
      "Epoch: 19700, Loss: 194.51194763183594\n",
      "Epoch: 19800, Loss: 194.47817993164062\n",
      "Epoch: 19900, Loss: 194.3592071533203\n",
      "Epoch: 20000, Loss: 194.34449768066406\n",
      "Epoch: 20100, Loss: 194.17269897460938\n",
      "Epoch: 20200, Loss: 194.1953582763672\n",
      "Epoch: 20300, Loss: 194.2454376220703\n",
      "Epoch: 20400, Loss: 194.12789916992188\n",
      "Epoch: 20500, Loss: 194.15097045898438\n",
      "Epoch: 20600, Loss: 193.9453887939453\n",
      "Epoch: 20700, Loss: 193.863037109375\n",
      "Epoch: 20800, Loss: 193.85458374023438\n",
      "Epoch: 20900, Loss: 193.8305206298828\n",
      "Epoch: 21000, Loss: 193.94866943359375\n",
      "Epoch: 21100, Loss: 193.64288330078125\n",
      "Epoch: 21200, Loss: 193.17926025390625\n",
      "Epoch: 21300, Loss: 193.14352416992188\n",
      "Epoch: 21400, Loss: 193.14581298828125\n",
      "Epoch: 21500, Loss: 193.1516571044922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21600, Loss: 193.17730712890625\n",
      "Epoch: 21700, Loss: 193.15573120117188\n",
      "Epoch: 21800, Loss: 193.13784790039062\n",
      "Epoch: 21900, Loss: 193.15281677246094\n",
      "Epoch: 22000, Loss: 193.45103454589844\n",
      "Epoch: 22100, Loss: 193.43963623046875\n",
      "Epoch: 22200, Loss: 192.69461059570312\n",
      "Epoch: 22300, Loss: 192.6163330078125\n",
      "Epoch: 22400, Loss: 192.50286865234375\n",
      "Epoch: 22500, Loss: 192.57586669921875\n",
      "Epoch: 22600, Loss: 192.52784729003906\n",
      "Epoch: 22700, Loss: 192.50929260253906\n",
      "Epoch: 22800, Loss: 192.52767944335938\n",
      "Epoch: 22900, Loss: 192.54489135742188\n",
      "Epoch: 23000, Loss: 192.50852966308594\n",
      "Epoch: 23100, Loss: 192.2737579345703\n",
      "Epoch: 23200, Loss: 192.26820373535156\n",
      "Epoch: 23300, Loss: 192.25341796875\n",
      "Epoch: 23400, Loss: 192.192626953125\n",
      "Epoch: 23500, Loss: 192.5074462890625\n",
      "Epoch: 23600, Loss: 190.98992919921875\n",
      "Epoch: 23700, Loss: 190.6031494140625\n",
      "Epoch: 23800, Loss: 190.54071044921875\n",
      "Epoch: 23900, Loss: 190.51620483398438\n",
      "Epoch: 24000, Loss: 190.52110290527344\n",
      "Epoch: 24100, Loss: 190.5200958251953\n",
      "Epoch: 24200, Loss: 190.51907348632812\n",
      "Epoch: 24300, Loss: 190.52484130859375\n",
      "Epoch: 24400, Loss: 190.51852416992188\n",
      "Epoch: 24500, Loss: 190.51918029785156\n",
      "Epoch: 24600, Loss: 190.52548217773438\n",
      "Epoch: 24700, Loss: 190.51438903808594\n",
      "Epoch: 24800, Loss: 190.54510498046875\n",
      "Epoch: 24900, Loss: 190.5462188720703\n",
      "Epoch: 25000, Loss: 191.48609924316406\n",
      "Epoch: 25100, Loss: 190.26943969726562\n",
      "Epoch: 25200, Loss: 190.1754913330078\n",
      "Epoch: 25300, Loss: 190.17910766601562\n",
      "Epoch: 25400, Loss: 190.17919921875\n",
      "Epoch: 25500, Loss: 190.16909790039062\n",
      "Epoch: 25600, Loss: 190.16903686523438\n",
      "Epoch: 25700, Loss: 190.1846923828125\n",
      "Epoch: 25800, Loss: 190.1744842529297\n",
      "Epoch: 25900, Loss: 190.17218017578125\n",
      "Epoch: 26000, Loss: 190.19894409179688\n",
      "Epoch: 26100, Loss: 190.1802215576172\n",
      "Epoch: 26200, Loss: 190.43675231933594\n",
      "Epoch: 26300, Loss: 190.0753173828125\n",
      "Epoch: 26400, Loss: 190.99876403808594\n",
      "Epoch: 26500, Loss: 189.40431213378906\n",
      "Epoch: 26600, Loss: 189.23504638671875\n",
      "Epoch: 26700, Loss: 189.13612365722656\n",
      "Epoch: 26800, Loss: 189.1138916015625\n",
      "Epoch: 26900, Loss: 189.13009643554688\n",
      "Epoch: 27000, Loss: 189.1151885986328\n",
      "Epoch: 27100, Loss: 189.11279296875\n",
      "Epoch: 27200, Loss: 189.11279296875\n",
      "Epoch: 27300, Loss: 189.11778259277344\n",
      "Epoch: 27400, Loss: 189.11312866210938\n",
      "Epoch: 27500, Loss: 189.11318969726562\n",
      "Epoch: 27600, Loss: 189.11880493164062\n",
      "Epoch: 27700, Loss: 189.4560546875\n",
      "Epoch: 27800, Loss: 189.19375610351562\n",
      "Epoch: 27900, Loss: 188.84963989257812\n",
      "Epoch: 28000, Loss: 188.43328857421875\n",
      "Epoch: 28100, Loss: 188.24221801757812\n",
      "Epoch: 28200, Loss: 188.22682189941406\n",
      "Epoch: 28300, Loss: 188.224365234375\n",
      "Epoch: 28400, Loss: 188.23300170898438\n",
      "Epoch: 28500, Loss: 188.2240447998047\n",
      "Epoch: 28600, Loss: 188.23141479492188\n",
      "Epoch: 28700, Loss: 188.22604370117188\n",
      "Epoch: 28800, Loss: 188.25411987304688\n",
      "Epoch: 28900, Loss: 188.3618927001953\n",
      "Epoch: 29000, Loss: 189.2081298828125\n",
      "Epoch: 29100, Loss: 188.2139434814453\n",
      "Epoch: 29200, Loss: 187.91470336914062\n",
      "Epoch: 29300, Loss: 187.868896484375\n",
      "Epoch: 29400, Loss: 187.86782836914062\n",
      "Epoch: 29500, Loss: 187.85360717773438\n",
      "Epoch: 29600, Loss: 187.85235595703125\n",
      "Epoch: 29700, Loss: 187.89651489257812\n",
      "Epoch: 29800, Loss: 187.9005126953125\n",
      "Epoch: 29900, Loss: 187.92398071289062\n",
      "Epoch: 30000, Loss: 187.9259796142578\n",
      "Epoch: 30100, Loss: 187.76434326171875\n",
      "Epoch: 30200, Loss: 187.3345489501953\n",
      "Epoch: 30300, Loss: 187.1998748779297\n",
      "Epoch: 30400, Loss: 187.18621826171875\n",
      "Epoch: 30500, Loss: 187.18321228027344\n",
      "Epoch: 30600, Loss: 187.1846160888672\n",
      "Epoch: 30700, Loss: 187.18142700195312\n",
      "Epoch: 30800, Loss: 187.18524169921875\n",
      "Epoch: 30900, Loss: 187.18508911132812\n",
      "Epoch: 31000, Loss: 187.19363403320312\n",
      "Epoch: 31100, Loss: 187.2144775390625\n",
      "Epoch: 31200, Loss: 187.69955444335938\n",
      "Epoch: 31300, Loss: 187.26136779785156\n",
      "Epoch: 31400, Loss: 186.97837829589844\n",
      "Epoch: 31500, Loss: 186.8350830078125\n",
      "Epoch: 31600, Loss: 187.1435546875\n",
      "Epoch: 31700, Loss: 186.87245178222656\n",
      "Epoch: 31800, Loss: 186.87472534179688\n",
      "Epoch: 31900, Loss: 186.92385864257812\n",
      "Epoch: 32000, Loss: 187.04107666015625\n",
      "Epoch: 32100, Loss: 186.59300231933594\n",
      "Epoch: 32200, Loss: 186.5374755859375\n",
      "Epoch: 32300, Loss: 186.56861877441406\n",
      "Epoch: 32400, Loss: 186.5184326171875\n",
      "Epoch: 32500, Loss: 186.50860595703125\n",
      "Epoch: 32600, Loss: 186.51080322265625\n",
      "Epoch: 32700, Loss: 186.52239990234375\n",
      "Epoch: 32800, Loss: 186.74005126953125\n",
      "Epoch: 32900, Loss: 186.73580932617188\n",
      "Epoch: 33000, Loss: 186.4334716796875\n",
      "Epoch: 33100, Loss: 186.5481414794922\n",
      "Epoch: 33200, Loss: 185.60574340820312\n",
      "Epoch: 33300, Loss: 185.48983764648438\n",
      "Epoch: 33400, Loss: 185.49777221679688\n",
      "Epoch: 33500, Loss: 185.47103881835938\n",
      "Epoch: 33600, Loss: 185.47889709472656\n",
      "Epoch: 33700, Loss: 185.48464965820312\n",
      "Epoch: 33800, Loss: 185.46389770507812\n",
      "Epoch: 33900, Loss: 185.55731201171875\n",
      "Epoch: 34000, Loss: 186.58543395996094\n",
      "Epoch: 34100, Loss: 184.98748779296875\n",
      "Epoch: 34200, Loss: 184.90164184570312\n",
      "Epoch: 34300, Loss: 184.88185119628906\n",
      "Epoch: 34400, Loss: 184.8686981201172\n",
      "Epoch: 34500, Loss: 184.87179565429688\n",
      "Epoch: 34600, Loss: 184.869873046875\n",
      "Epoch: 34700, Loss: 184.8715362548828\n",
      "Epoch: 34800, Loss: 184.87310791015625\n",
      "Epoch: 34900, Loss: 184.89964294433594\n",
      "Epoch: 35000, Loss: 185.02487182617188\n",
      "Epoch: 35100, Loss: 184.97569274902344\n",
      "Epoch: 35200, Loss: 184.97003173828125\n",
      "Epoch: 35300, Loss: 184.64520263671875\n",
      "Epoch: 35400, Loss: 184.71401977539062\n",
      "Epoch: 35500, Loss: 184.67239379882812\n",
      "Epoch: 35600, Loss: 184.5919647216797\n",
      "Epoch: 35700, Loss: 184.589111328125\n",
      "Epoch: 35800, Loss: 184.59251403808594\n",
      "Epoch: 35900, Loss: 184.58380126953125\n",
      "Epoch: 36000, Loss: 184.58566284179688\n",
      "Epoch: 36100, Loss: 184.61038208007812\n",
      "Epoch: 36200, Loss: 184.62210083007812\n",
      "Epoch: 36300, Loss: 184.4879608154297\n",
      "Epoch: 36400, Loss: 183.34744262695312\n",
      "Epoch: 36500, Loss: 183.30081176757812\n",
      "Epoch: 36600, Loss: 183.27340698242188\n",
      "Epoch: 36700, Loss: 183.27357482910156\n",
      "Epoch: 36800, Loss: 183.27114868164062\n",
      "Epoch: 36900, Loss: 183.27194213867188\n",
      "Epoch: 37000, Loss: 183.27130126953125\n",
      "Epoch: 37100, Loss: 183.27359008789062\n",
      "Epoch: 37200, Loss: 183.27609252929688\n",
      "Epoch: 37300, Loss: 183.27407836914062\n",
      "Epoch: 37400, Loss: 183.2771759033203\n",
      "Epoch: 37500, Loss: 183.27413940429688\n",
      "Epoch: 37600, Loss: 183.274169921875\n",
      "Epoch: 37700, Loss: 183.2789764404297\n",
      "Epoch: 37800, Loss: 183.2772674560547\n",
      "Epoch: 37900, Loss: 183.28115844726562\n",
      "Epoch: 38000, Loss: 183.28512573242188\n",
      "Epoch: 38100, Loss: 183.3211669921875\n",
      "Epoch: 38200, Loss: 183.4698486328125\n",
      "Epoch: 38300, Loss: 183.7308807373047\n",
      "Epoch: 38400, Loss: 182.90850830078125\n",
      "Epoch: 38500, Loss: 182.9320831298828\n",
      "Epoch: 38600, Loss: 182.8341064453125\n",
      "Epoch: 38700, Loss: 182.82151794433594\n",
      "Epoch: 38800, Loss: 182.97723388671875\n",
      "Epoch: 38900, Loss: 182.75094604492188\n",
      "Epoch: 39000, Loss: 182.71678161621094\n",
      "Epoch: 39100, Loss: 182.72592163085938\n",
      "Epoch: 39200, Loss: 182.72018432617188\n",
      "Epoch: 39300, Loss: 182.72012329101562\n",
      "Epoch: 39400, Loss: 182.79000854492188\n",
      "Epoch: 39500, Loss: 182.75283813476562\n",
      "Epoch: 39600, Loss: 183.293701171875\n",
      "Epoch: 39700, Loss: 182.5936737060547\n",
      "Epoch: 39800, Loss: 182.4859161376953\n",
      "Epoch: 39900, Loss: 182.25144958496094\n",
      "Epoch: 40000, Loss: 182.30960083007812\n",
      "Epoch: 40100, Loss: 182.2484893798828\n",
      "Epoch: 40200, Loss: 182.16061401367188\n",
      "Epoch: 40300, Loss: 182.18704223632812\n",
      "Epoch: 40400, Loss: 182.21292114257812\n",
      "Epoch: 40500, Loss: 182.17083740234375\n",
      "Epoch: 40600, Loss: 182.2202606201172\n",
      "Epoch: 40700, Loss: 182.4354248046875\n",
      "Epoch: 40800, Loss: 181.75958251953125\n",
      "Epoch: 40900, Loss: 181.65635681152344\n",
      "Epoch: 41000, Loss: 181.6572265625\n",
      "Epoch: 41100, Loss: 181.68748474121094\n",
      "Epoch: 41200, Loss: 181.73484802246094\n",
      "Epoch: 41300, Loss: 182.01287841796875\n",
      "Epoch: 41400, Loss: 181.67141723632812\n",
      "Epoch: 41500, Loss: 181.9212188720703\n",
      "Epoch: 41600, Loss: 181.26266479492188\n",
      "Epoch: 41700, Loss: 182.17205810546875\n",
      "Epoch: 41800, Loss: 181.02886962890625\n",
      "Epoch: 41900, Loss: 180.81027221679688\n",
      "Epoch: 42000, Loss: 180.78973388671875\n",
      "Epoch: 42100, Loss: 180.77725219726562\n",
      "Epoch: 42200, Loss: 180.77835083007812\n",
      "Epoch: 42300, Loss: 180.77804565429688\n",
      "Epoch: 42400, Loss: 180.77847290039062\n",
      "Epoch: 42500, Loss: 180.78732299804688\n",
      "Epoch: 42600, Loss: 180.7757568359375\n",
      "Epoch: 42700, Loss: 180.84829711914062\n",
      "Epoch: 42800, Loss: 180.775390625\n",
      "Epoch: 42900, Loss: 180.77877807617188\n",
      "Epoch: 43000, Loss: 180.798583984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43100, Loss: 180.8695068359375\n",
      "Epoch: 43200, Loss: 180.82949829101562\n",
      "Epoch: 43300, Loss: 180.592041015625\n",
      "Epoch: 43400, Loss: 180.59262084960938\n",
      "Epoch: 43500, Loss: 180.59890747070312\n",
      "Epoch: 43600, Loss: 180.71180725097656\n",
      "Epoch: 43700, Loss: 181.19619750976562\n",
      "Epoch: 43800, Loss: 180.48126220703125\n",
      "Epoch: 43900, Loss: 179.97445678710938\n",
      "Epoch: 44000, Loss: 179.95687866210938\n",
      "Epoch: 44100, Loss: 179.96441650390625\n",
      "Epoch: 44200, Loss: 179.96160888671875\n",
      "Epoch: 44300, Loss: 179.973388671875\n",
      "Epoch: 44400, Loss: 180.020263671875\n",
      "Epoch: 44500, Loss: 180.05523681640625\n",
      "Epoch: 44600, Loss: 179.93373107910156\n",
      "Epoch: 44700, Loss: 179.949462890625\n",
      "Epoch: 44800, Loss: 180.04342651367188\n",
      "Epoch: 44900, Loss: 180.46603393554688\n",
      "Epoch: 45000, Loss: 179.80250549316406\n",
      "Epoch: 45100, Loss: 179.6474151611328\n",
      "Epoch: 45200, Loss: 179.70582580566406\n",
      "Epoch: 45300, Loss: 179.5970458984375\n",
      "Epoch: 45400, Loss: 179.69859313964844\n",
      "Epoch: 45500, Loss: 179.46401977539062\n",
      "Epoch: 45600, Loss: 179.42132568359375\n",
      "Epoch: 45700, Loss: 179.49586486816406\n",
      "Epoch: 45800, Loss: 179.31121826171875\n",
      "Epoch: 45900, Loss: 179.51010131835938\n",
      "Epoch: 46000, Loss: 179.26190185546875\n",
      "Epoch: 46100, Loss: 179.2657012939453\n",
      "Epoch: 46200, Loss: 179.08306884765625\n",
      "Epoch: 46300, Loss: 179.08160400390625\n",
      "Epoch: 46400, Loss: 179.0896453857422\n",
      "Epoch: 46500, Loss: 179.07440185546875\n",
      "Epoch: 46600, Loss: 179.09548950195312\n",
      "Epoch: 46700, Loss: 179.36634826660156\n",
      "Epoch: 46800, Loss: 179.09017944335938\n",
      "Epoch: 46900, Loss: 179.13702392578125\n",
      "Epoch: 47000, Loss: 179.77584838867188\n",
      "Epoch: 47100, Loss: 177.61532592773438\n",
      "Epoch: 47200, Loss: 177.5157012939453\n",
      "Epoch: 47300, Loss: 177.48629760742188\n",
      "Epoch: 47400, Loss: 177.48001098632812\n",
      "Epoch: 47500, Loss: 177.48048400878906\n",
      "Epoch: 47600, Loss: 177.48159790039062\n",
      "Epoch: 47700, Loss: 177.48507690429688\n",
      "Epoch: 47800, Loss: 177.48257446289062\n",
      "Epoch: 47900, Loss: 177.482421875\n",
      "Epoch: 48000, Loss: 177.48294067382812\n",
      "Epoch: 48100, Loss: 177.48312377929688\n",
      "Epoch: 48200, Loss: 177.48484802246094\n",
      "Epoch: 48300, Loss: 177.48358154296875\n",
      "Epoch: 48400, Loss: 177.487548828125\n",
      "Epoch: 48500, Loss: 177.484375\n",
      "Epoch: 48600, Loss: 177.48605346679688\n",
      "Epoch: 48700, Loss: 177.48773193359375\n",
      "Epoch: 48800, Loss: 177.48828125\n",
      "Epoch: 48900, Loss: 177.485107421875\n",
      "Epoch: 49000, Loss: 177.48529052734375\n",
      "Epoch: 49100, Loss: 177.48599243164062\n",
      "Epoch: 49200, Loss: 177.525390625\n",
      "Epoch: 49300, Loss: 178.00689697265625\n",
      "Epoch: 49400, Loss: 177.06385803222656\n",
      "Epoch: 49500, Loss: 176.915771484375\n",
      "Epoch: 49600, Loss: 176.891845703125\n",
      "Epoch: 49700, Loss: 176.89089965820312\n",
      "Epoch: 49800, Loss: 176.8931121826172\n",
      "Epoch: 49900, Loss: 176.8929443359375\n",
      "Epoch: 50000, Loss: 176.89442443847656\n",
      "Epoch: 50100, Loss: 176.89627075195312\n",
      "Epoch: 50200, Loss: 176.8968963623047\n",
      "Epoch: 50300, Loss: 176.89466857910156\n",
      "Epoch: 50400, Loss: 176.91949462890625\n",
      "Epoch: 50500, Loss: 176.90802001953125\n",
      "Epoch: 50600, Loss: 176.89295959472656\n",
      "Epoch: 50700, Loss: 176.90948486328125\n",
      "Epoch: 50800, Loss: 176.96517944335938\n",
      "Epoch: 50900, Loss: 177.142578125\n",
      "Epoch: 51000, Loss: 176.662841796875\n",
      "Epoch: 51100, Loss: 176.41204833984375\n",
      "Epoch: 51200, Loss: 176.3125\n",
      "Epoch: 51300, Loss: 176.24444580078125\n",
      "Epoch: 51400, Loss: 176.26206970214844\n",
      "Epoch: 51500, Loss: 176.24435424804688\n",
      "Epoch: 51600, Loss: 176.2457275390625\n",
      "Epoch: 51700, Loss: 176.24737548828125\n",
      "Epoch: 51800, Loss: 176.2452850341797\n",
      "Epoch: 51900, Loss: 176.26873779296875\n",
      "Epoch: 52000, Loss: 176.39874267578125\n",
      "Epoch: 52100, Loss: 176.28363037109375\n",
      "Epoch: 52200, Loss: 176.47952270507812\n",
      "Epoch: 52300, Loss: 176.25201416015625\n",
      "Epoch: 52400, Loss: 176.5098876953125\n",
      "Epoch: 52500, Loss: 176.19808959960938\n",
      "Epoch: 52600, Loss: 175.79551696777344\n",
      "Epoch: 52700, Loss: 175.5882568359375\n",
      "Epoch: 52800, Loss: 175.58619689941406\n",
      "Epoch: 52900, Loss: 175.58090209960938\n",
      "Epoch: 53000, Loss: 175.5810546875\n",
      "Epoch: 53100, Loss: 175.58006286621094\n",
      "Epoch: 53200, Loss: 175.58685302734375\n",
      "Epoch: 53300, Loss: 175.60885620117188\n",
      "Epoch: 53400, Loss: 175.58755493164062\n",
      "Epoch: 53500, Loss: 175.60107421875\n",
      "Epoch: 53600, Loss: 175.60061645507812\n",
      "Epoch: 53700, Loss: 175.70645141601562\n",
      "Epoch: 53800, Loss: 175.7384033203125\n",
      "Epoch: 53900, Loss: 175.7834014892578\n",
      "Epoch: 54000, Loss: 175.38246154785156\n",
      "Epoch: 54100, Loss: 175.28363037109375\n",
      "Epoch: 54200, Loss: 175.25064086914062\n",
      "Epoch: 54300, Loss: 175.1502685546875\n",
      "Epoch: 54400, Loss: 175.21221923828125\n",
      "Epoch: 54500, Loss: 175.33059692382812\n",
      "Epoch: 54600, Loss: 175.1005859375\n",
      "Epoch: 54700, Loss: 175.06048583984375\n",
      "Epoch: 54800, Loss: 175.0254364013672\n",
      "Epoch: 54900, Loss: 174.9930419921875\n",
      "Epoch: 55000, Loss: 174.98744201660156\n",
      "Epoch: 55100, Loss: 175.07330322265625\n",
      "Epoch: 55200, Loss: 176.45010375976562\n",
      "Epoch: 55300, Loss: 174.42413330078125\n",
      "Epoch: 55400, Loss: 174.24803161621094\n",
      "Epoch: 55500, Loss: 174.24661254882812\n",
      "Epoch: 55600, Loss: 174.2446746826172\n",
      "Epoch: 55700, Loss: 174.24520874023438\n",
      "Epoch: 55800, Loss: 174.24453735351562\n",
      "Epoch: 55900, Loss: 174.25042724609375\n",
      "Epoch: 56000, Loss: 174.24697875976562\n",
      "Epoch: 56100, Loss: 174.24969482421875\n",
      "Epoch: 56200, Loss: 174.249267578125\n",
      "Epoch: 56300, Loss: 174.2469024658203\n",
      "Epoch: 56400, Loss: 174.25277709960938\n",
      "Epoch: 56500, Loss: 174.2498779296875\n",
      "Epoch: 56600, Loss: 174.24594116210938\n",
      "Epoch: 56700, Loss: 174.2467041015625\n",
      "Epoch: 56800, Loss: 174.28834533691406\n",
      "Epoch: 56900, Loss: 174.41522216796875\n",
      "Epoch: 57000, Loss: 174.49195861816406\n",
      "Epoch: 57100, Loss: 174.05836486816406\n",
      "Epoch: 57200, Loss: 173.9368133544922\n",
      "Epoch: 57300, Loss: 173.93429565429688\n",
      "Epoch: 57400, Loss: 173.94357299804688\n",
      "Epoch: 57500, Loss: 173.919921875\n",
      "Epoch: 57600, Loss: 173.916748046875\n",
      "Epoch: 57700, Loss: 173.89718627929688\n",
      "Epoch: 57800, Loss: 173.91162109375\n",
      "Epoch: 57900, Loss: 174.39939880371094\n",
      "Epoch: 58000, Loss: 174.45166015625\n",
      "Epoch: 58100, Loss: 174.0845489501953\n",
      "Epoch: 58200, Loss: 173.4270477294922\n",
      "Epoch: 58300, Loss: 173.32518005371094\n",
      "Epoch: 58400, Loss: 173.31103515625\n",
      "Epoch: 58500, Loss: 173.34237670898438\n",
      "Epoch: 58600, Loss: 173.29896545410156\n",
      "Epoch: 58700, Loss: 173.28439331054688\n",
      "Epoch: 58800, Loss: 173.29608154296875\n",
      "Epoch: 58900, Loss: 173.31314086914062\n",
      "Epoch: 59000, Loss: 173.28146362304688\n",
      "Epoch: 59100, Loss: 173.32269287109375\n",
      "Epoch: 59200, Loss: 173.37301635742188\n",
      "Epoch: 59300, Loss: 173.38296508789062\n",
      "Epoch: 59400, Loss: 173.32119750976562\n",
      "Epoch: 59500, Loss: 173.24754333496094\n",
      "Epoch: 59600, Loss: 172.99542236328125\n",
      "Epoch: 59700, Loss: 172.9603271484375\n",
      "Epoch: 59800, Loss: 172.95166015625\n",
      "Epoch: 59900, Loss: 172.9378662109375\n",
      "Epoch: 60000, Loss: 172.94842529296875\n",
      "Epoch: 60100, Loss: 173.11260986328125\n",
      "Epoch: 60200, Loss: 173.31851196289062\n",
      "Epoch: 60300, Loss: 172.73013305664062\n",
      "Epoch: 60400, Loss: 172.70985412597656\n",
      "Epoch: 60500, Loss: 172.70928955078125\n",
      "Epoch: 60600, Loss: 172.7345428466797\n",
      "Epoch: 60700, Loss: 172.75921630859375\n",
      "Epoch: 60800, Loss: 172.74472045898438\n",
      "Epoch: 60900, Loss: 173.08787536621094\n",
      "Epoch: 61000, Loss: 172.69476318359375\n",
      "Epoch: 61100, Loss: 172.3307342529297\n",
      "Epoch: 61200, Loss: 172.18707275390625\n",
      "Epoch: 61300, Loss: 172.18670654296875\n",
      "Epoch: 61400, Loss: 172.17828369140625\n",
      "Epoch: 61500, Loss: 172.18531799316406\n",
      "Epoch: 61600, Loss: 172.18496704101562\n",
      "Epoch: 61700, Loss: 172.1826171875\n",
      "Epoch: 61800, Loss: 172.20736694335938\n",
      "Epoch: 61900, Loss: 172.20114135742188\n",
      "Epoch: 62000, Loss: 172.23443603515625\n",
      "Epoch: 62100, Loss: 172.2335968017578\n",
      "Epoch: 62200, Loss: 172.4288330078125\n",
      "Epoch: 62300, Loss: 172.20555114746094\n",
      "Epoch: 62400, Loss: 172.07046508789062\n",
      "Epoch: 62500, Loss: 172.1409454345703\n",
      "Epoch: 62600, Loss: 172.23757934570312\n",
      "Epoch: 62700, Loss: 172.322509765625\n",
      "Epoch: 62800, Loss: 171.61508178710938\n",
      "Epoch: 62900, Loss: 171.62741088867188\n",
      "Epoch: 63000, Loss: 171.41159057617188\n",
      "Epoch: 63100, Loss: 171.39865112304688\n",
      "Epoch: 63200, Loss: 171.4153594970703\n",
      "Epoch: 63300, Loss: 171.44773864746094\n",
      "Epoch: 63400, Loss: 171.72100830078125\n",
      "Epoch: 63500, Loss: 171.35806274414062\n",
      "Epoch: 63600, Loss: 171.35638427734375\n",
      "Epoch: 63700, Loss: 171.79344177246094\n",
      "Epoch: 63800, Loss: 171.307861328125\n",
      "Epoch: 63900, Loss: 171.279296875\n",
      "Epoch: 64000, Loss: 170.0902862548828\n",
      "Epoch: 64100, Loss: 170.07144165039062\n",
      "Epoch: 64200, Loss: 170.07025146484375\n",
      "Epoch: 64300, Loss: 170.06954956054688\n",
      "Epoch: 64400, Loss: 170.07095336914062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64500, Loss: 170.072265625\n",
      "Epoch: 64600, Loss: 170.07009887695312\n",
      "Epoch: 64700, Loss: 170.0702667236328\n",
      "Epoch: 64800, Loss: 170.07022094726562\n",
      "Epoch: 64900, Loss: 170.07205200195312\n",
      "Epoch: 65000, Loss: 170.06930541992188\n",
      "Epoch: 65100, Loss: 170.07057189941406\n",
      "Epoch: 65200, Loss: 170.0712432861328\n",
      "Epoch: 65300, Loss: 170.07115173339844\n",
      "Epoch: 65400, Loss: 170.07305908203125\n",
      "Epoch: 65500, Loss: 170.0767822265625\n",
      "Epoch: 65600, Loss: 170.17832946777344\n",
      "Epoch: 65700, Loss: 170.106201171875\n",
      "Epoch: 65800, Loss: 170.2021484375\n",
      "Epoch: 65900, Loss: 170.17787170410156\n",
      "Epoch: 66000, Loss: 170.319091796875\n",
      "Epoch: 66100, Loss: 170.21282958984375\n",
      "Epoch: 66200, Loss: 169.9867401123047\n",
      "Epoch: 66300, Loss: 169.83120727539062\n",
      "Epoch: 66400, Loss: 169.90139770507812\n",
      "Epoch: 66500, Loss: 169.67054748535156\n",
      "Epoch: 66600, Loss: 169.65264892578125\n",
      "Epoch: 66700, Loss: 169.6673126220703\n",
      "Epoch: 66800, Loss: 169.64773559570312\n",
      "Epoch: 66900, Loss: 169.64923095703125\n",
      "Epoch: 67000, Loss: 170.24734497070312\n",
      "Epoch: 67100, Loss: 169.62779235839844\n",
      "Epoch: 67200, Loss: 171.4276123046875\n",
      "Epoch: 67300, Loss: 169.12001037597656\n",
      "Epoch: 67400, Loss: 169.01910400390625\n",
      "Epoch: 67500, Loss: 168.83726501464844\n",
      "Epoch: 67600, Loss: 168.82980346679688\n",
      "Epoch: 67700, Loss: 168.829345703125\n",
      "Epoch: 67800, Loss: 168.8309326171875\n",
      "Epoch: 67900, Loss: 168.8355255126953\n",
      "Epoch: 68000, Loss: 168.83285522460938\n",
      "Epoch: 68100, Loss: 168.8353271484375\n",
      "Epoch: 68200, Loss: 168.8369903564453\n",
      "Epoch: 68300, Loss: 168.8455352783203\n",
      "Epoch: 68400, Loss: 168.83493041992188\n",
      "Epoch: 68500, Loss: 168.83795166015625\n",
      "Epoch: 68600, Loss: 168.83322143554688\n",
      "Epoch: 68700, Loss: 168.85629272460938\n",
      "Epoch: 68800, Loss: 168.94964599609375\n",
      "Epoch: 68900, Loss: 169.07350158691406\n",
      "Epoch: 69000, Loss: 168.89328002929688\n",
      "Epoch: 69100, Loss: 168.6154022216797\n",
      "Epoch: 69200, Loss: 168.51268005371094\n",
      "Epoch: 69300, Loss: 168.26895141601562\n",
      "Epoch: 69400, Loss: 168.4071044921875\n",
      "Epoch: 69500, Loss: 168.24954223632812\n",
      "Epoch: 69600, Loss: 168.27664184570312\n",
      "Epoch: 69700, Loss: 168.88522338867188\n",
      "Epoch: 69800, Loss: 167.92819213867188\n",
      "Epoch: 69900, Loss: 167.5718994140625\n",
      "Epoch: 70000, Loss: 167.553955078125\n",
      "Epoch: 70100, Loss: 167.552490234375\n",
      "Epoch: 70200, Loss: 167.55355834960938\n",
      "Epoch: 70300, Loss: 167.5549774169922\n",
      "Epoch: 70400, Loss: 167.55462646484375\n",
      "Epoch: 70500, Loss: 167.5522003173828\n",
      "Epoch: 70600, Loss: 167.5518798828125\n",
      "Epoch: 70700, Loss: 167.55331420898438\n",
      "Epoch: 70800, Loss: 167.55137634277344\n",
      "Epoch: 70900, Loss: 167.55361938476562\n",
      "Epoch: 71000, Loss: 167.55516052246094\n",
      "Epoch: 71100, Loss: 167.57183837890625\n",
      "Epoch: 71200, Loss: 167.59915161132812\n",
      "Epoch: 71300, Loss: 167.6470947265625\n",
      "Epoch: 71400, Loss: 168.2549591064453\n",
      "Epoch: 71500, Loss: 167.16163635253906\n",
      "Epoch: 71600, Loss: 167.11077880859375\n",
      "Epoch: 71700, Loss: 167.08489990234375\n",
      "Epoch: 71800, Loss: 167.06272888183594\n",
      "Epoch: 71900, Loss: 167.05853271484375\n",
      "Epoch: 72000, Loss: 167.06723022460938\n",
      "Epoch: 72100, Loss: 167.05799865722656\n",
      "Epoch: 72200, Loss: 167.07046508789062\n",
      "Epoch: 72300, Loss: 167.17987060546875\n",
      "Epoch: 72400, Loss: 167.28277587890625\n",
      "Epoch: 72500, Loss: 167.2091522216797\n",
      "Epoch: 72600, Loss: 167.01730346679688\n",
      "Epoch: 72700, Loss: 166.96255493164062\n",
      "Epoch: 72800, Loss: 166.98486328125\n",
      "Epoch: 72900, Loss: 168.64434814453125\n",
      "Epoch: 73000, Loss: 166.3692626953125\n",
      "Epoch: 73100, Loss: 166.2518310546875\n",
      "Epoch: 73200, Loss: 166.21636962890625\n",
      "Epoch: 73300, Loss: 166.2236328125\n",
      "Epoch: 73400, Loss: 166.20851135253906\n",
      "Epoch: 73500, Loss: 166.21319580078125\n",
      "Epoch: 73600, Loss: 166.2257843017578\n",
      "Epoch: 73700, Loss: 166.23464965820312\n",
      "Epoch: 73800, Loss: 166.22019958496094\n",
      "Epoch: 73900, Loss: 166.2186737060547\n",
      "Epoch: 74000, Loss: 166.2331085205078\n",
      "Epoch: 74100, Loss: 166.2657928466797\n",
      "Epoch: 74200, Loss: 166.31521606445312\n",
      "Epoch: 74300, Loss: 166.4564208984375\n",
      "Epoch: 74400, Loss: 165.56246948242188\n",
      "Epoch: 74500, Loss: 165.46389770507812\n",
      "Epoch: 74600, Loss: 165.46099853515625\n",
      "Epoch: 74700, Loss: 165.45895385742188\n",
      "Epoch: 74800, Loss: 165.45863342285156\n",
      "Epoch: 74900, Loss: 165.4580841064453\n",
      "Epoch: 75000, Loss: 165.45826721191406\n",
      "Epoch: 75100, Loss: 165.45770263671875\n",
      "Epoch: 75200, Loss: 165.4598388671875\n",
      "Epoch: 75300, Loss: 165.46148681640625\n",
      "Epoch: 75400, Loss: 165.4608917236328\n",
      "Epoch: 75500, Loss: 165.46127319335938\n",
      "Epoch: 75600, Loss: 165.45973205566406\n",
      "Epoch: 75700, Loss: 165.4750213623047\n",
      "Epoch: 75800, Loss: 165.48150634765625\n",
      "Epoch: 75900, Loss: 165.46107482910156\n",
      "Epoch: 76000, Loss: 165.47525024414062\n",
      "Epoch: 76100, Loss: 165.70278930664062\n",
      "Epoch: 76200, Loss: 165.25881958007812\n",
      "Epoch: 76300, Loss: 165.35089111328125\n",
      "Epoch: 76400, Loss: 165.221435546875\n",
      "Epoch: 76500, Loss: 165.25115966796875\n",
      "Epoch: 76600, Loss: 165.30657958984375\n",
      "Epoch: 76700, Loss: 165.14366149902344\n",
      "Epoch: 76800, Loss: 165.14878845214844\n",
      "Epoch: 76900, Loss: 165.10496520996094\n",
      "Epoch: 77000, Loss: 165.03030395507812\n",
      "Epoch: 77100, Loss: 165.29254150390625\n",
      "Epoch: 77200, Loss: 165.15707397460938\n",
      "Epoch: 77300, Loss: 165.19705200195312\n",
      "Epoch: 77400, Loss: 165.26788330078125\n",
      "Epoch: 77500, Loss: 165.02853393554688\n",
      "Epoch: 77600, Loss: 164.16690063476562\n",
      "Epoch: 77700, Loss: 164.0006866455078\n",
      "Epoch: 77800, Loss: 163.98609924316406\n",
      "Epoch: 77900, Loss: 163.98345947265625\n",
      "Epoch: 78000, Loss: 163.98654174804688\n",
      "Epoch: 78100, Loss: 163.98455810546875\n",
      "Epoch: 78200, Loss: 163.98484802246094\n",
      "Epoch: 78300, Loss: 163.988037109375\n",
      "Epoch: 78400, Loss: 163.9884796142578\n",
      "Epoch: 78500, Loss: 163.98428344726562\n",
      "Epoch: 78600, Loss: 163.98309326171875\n",
      "Epoch: 78700, Loss: 164.00338745117188\n",
      "Epoch: 78800, Loss: 164.04783630371094\n",
      "Epoch: 78900, Loss: 164.13027954101562\n",
      "Epoch: 79000, Loss: 163.89663696289062\n",
      "Epoch: 79100, Loss: 163.83474731445312\n",
      "Epoch: 79200, Loss: 163.826171875\n",
      "Epoch: 79300, Loss: 163.827880859375\n",
      "Epoch: 79400, Loss: 163.8298797607422\n",
      "Epoch: 79500, Loss: 163.82907104492188\n",
      "Epoch: 79600, Loss: 163.82923889160156\n",
      "Epoch: 79700, Loss: 163.86715698242188\n",
      "Epoch: 79800, Loss: 164.37161254882812\n",
      "Epoch: 79900, Loss: 165.1170196533203\n",
      "Epoch: 80000, Loss: 163.27955627441406\n",
      "Epoch: 80100, Loss: 163.1238555908203\n",
      "Epoch: 80200, Loss: 163.19229125976562\n",
      "Epoch: 80300, Loss: 163.1090545654297\n",
      "Epoch: 80400, Loss: 163.10337829589844\n",
      "Epoch: 80500, Loss: 163.11337280273438\n",
      "Epoch: 80600, Loss: 163.12437438964844\n",
      "Epoch: 80700, Loss: 163.11012268066406\n",
      "Epoch: 80800, Loss: 163.1132049560547\n",
      "Epoch: 80900, Loss: 163.15679931640625\n",
      "Epoch: 81000, Loss: 163.3885040283203\n",
      "Epoch: 81100, Loss: 163.11378479003906\n",
      "Epoch: 81200, Loss: 162.9952392578125\n",
      "Epoch: 81300, Loss: 162.94602966308594\n",
      "Epoch: 81400, Loss: 163.23927307128906\n",
      "Epoch: 81500, Loss: 163.01513671875\n",
      "Epoch: 81600, Loss: 162.86672973632812\n",
      "Epoch: 81700, Loss: 162.50241088867188\n",
      "Epoch: 81800, Loss: 162.4193115234375\n",
      "Epoch: 81900, Loss: 162.40713500976562\n",
      "Epoch: 82000, Loss: 162.39739990234375\n",
      "Epoch: 82100, Loss: 162.422119140625\n",
      "Epoch: 82200, Loss: 162.40408325195312\n",
      "Epoch: 82300, Loss: 162.40406799316406\n",
      "Epoch: 82400, Loss: 162.3992156982422\n",
      "Epoch: 82500, Loss: 162.3970947265625\n",
      "Epoch: 82600, Loss: 162.39913940429688\n",
      "Epoch: 82700, Loss: 162.4105224609375\n",
      "Epoch: 82800, Loss: 162.5787353515625\n",
      "Epoch: 82900, Loss: 162.43136596679688\n",
      "Epoch: 83000, Loss: 162.20899963378906\n",
      "Epoch: 83100, Loss: 162.27108764648438\n",
      "Epoch: 83200, Loss: 161.99842834472656\n",
      "Epoch: 83300, Loss: 162.15304565429688\n",
      "Epoch: 83400, Loss: 162.01585388183594\n",
      "Epoch: 83500, Loss: 161.78573608398438\n",
      "Epoch: 83600, Loss: 161.69863891601562\n",
      "Epoch: 83700, Loss: 161.6942138671875\n",
      "Epoch: 83800, Loss: 161.705810546875\n",
      "Epoch: 83900, Loss: 161.6986083984375\n",
      "Epoch: 84000, Loss: 161.70089721679688\n",
      "Epoch: 84100, Loss: 161.70053100585938\n",
      "Epoch: 84200, Loss: 161.74111938476562\n",
      "Epoch: 84300, Loss: 161.75845336914062\n",
      "Epoch: 84400, Loss: 161.70526123046875\n",
      "Epoch: 84500, Loss: 161.6544647216797\n",
      "Epoch: 84600, Loss: 162.06101989746094\n",
      "Epoch: 84700, Loss: 161.46759033203125\n",
      "Epoch: 84800, Loss: 161.45687866210938\n",
      "Epoch: 84900, Loss: 161.43397521972656\n",
      "Epoch: 85000, Loss: 161.40469360351562\n",
      "Epoch: 85100, Loss: 161.4402313232422\n",
      "Epoch: 85200, Loss: 161.838623046875\n",
      "Epoch: 85300, Loss: 161.3038330078125\n",
      "Epoch: 85400, Loss: 161.25950622558594\n",
      "Epoch: 85500, Loss: 161.1885223388672\n",
      "Epoch: 85600, Loss: 161.20364379882812\n",
      "Epoch: 85700, Loss: 161.13116455078125\n",
      "Epoch: 85800, Loss: 161.1599578857422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85900, Loss: 161.14657592773438\n",
      "Epoch: 86000, Loss: 161.7760009765625\n",
      "Epoch: 86100, Loss: 161.08160400390625\n",
      "Epoch: 86200, Loss: 160.63182067871094\n",
      "Epoch: 86300, Loss: 160.5630645751953\n",
      "Epoch: 86400, Loss: 160.57046508789062\n",
      "Epoch: 86500, Loss: 160.56716918945312\n",
      "Epoch: 86600, Loss: 160.56893920898438\n",
      "Epoch: 86700, Loss: 160.56515502929688\n",
      "Epoch: 86800, Loss: 160.56134033203125\n",
      "Epoch: 86900, Loss: 160.5604705810547\n",
      "Epoch: 87000, Loss: 160.56253051757812\n",
      "Epoch: 87100, Loss: 160.56613159179688\n",
      "Epoch: 87200, Loss: 160.57449340820312\n",
      "Epoch: 87300, Loss: 160.63375854492188\n",
      "Epoch: 87400, Loss: 160.56436157226562\n",
      "Epoch: 87500, Loss: 160.60076904296875\n",
      "Epoch: 87600, Loss: 160.87225341796875\n",
      "Epoch: 87700, Loss: 160.2130889892578\n",
      "Epoch: 87800, Loss: 160.13194274902344\n",
      "Epoch: 87900, Loss: 160.13031005859375\n",
      "Epoch: 88000, Loss: 160.07705688476562\n",
      "Epoch: 88100, Loss: 160.09495544433594\n",
      "Epoch: 88200, Loss: 160.13282775878906\n",
      "Epoch: 88300, Loss: 160.08111572265625\n",
      "Epoch: 88400, Loss: 160.06979370117188\n",
      "Epoch: 88500, Loss: 160.06796264648438\n",
      "Epoch: 88600, Loss: 160.06385803222656\n",
      "Epoch: 88700, Loss: 160.06222534179688\n",
      "Epoch: 88800, Loss: 160.14932250976562\n",
      "Epoch: 88900, Loss: 160.79690551757812\n",
      "Epoch: 89000, Loss: 160.92343139648438\n",
      "Epoch: 89100, Loss: 159.62869262695312\n",
      "Epoch: 89200, Loss: 159.61328125\n",
      "Epoch: 89300, Loss: 159.5206298828125\n",
      "Epoch: 89400, Loss: 159.48944091796875\n",
      "Epoch: 89500, Loss: 159.4659423828125\n",
      "Epoch: 89600, Loss: 159.4651336669922\n",
      "Epoch: 89700, Loss: 159.46560668945312\n",
      "Epoch: 89800, Loss: 159.4693603515625\n",
      "Epoch: 89900, Loss: 159.46795654296875\n",
      "Epoch: 90000, Loss: 159.47775268554688\n",
      "Epoch: 90100, Loss: 159.47525024414062\n",
      "Epoch: 90200, Loss: 159.5370330810547\n",
      "Epoch: 90300, Loss: 159.5178680419922\n",
      "Epoch: 90400, Loss: 161.17059326171875\n",
      "Epoch: 90500, Loss: 159.222900390625\n",
      "Epoch: 90600, Loss: 158.82887268066406\n",
      "Epoch: 90700, Loss: 158.82423400878906\n",
      "Epoch: 90800, Loss: 158.8191680908203\n",
      "Epoch: 90900, Loss: 158.81817626953125\n",
      "Epoch: 91000, Loss: 158.8193817138672\n",
      "Epoch: 91100, Loss: 158.82498168945312\n",
      "Epoch: 91200, Loss: 158.82748413085938\n",
      "Epoch: 91300, Loss: 158.8199462890625\n",
      "Epoch: 91400, Loss: 158.8319549560547\n",
      "Epoch: 91500, Loss: 158.82077026367188\n",
      "Epoch: 91600, Loss: 158.94049072265625\n",
      "Epoch: 91700, Loss: 159.60992431640625\n",
      "Epoch: 91800, Loss: 158.7852020263672\n",
      "Epoch: 91900, Loss: 160.19210815429688\n",
      "Epoch: 92000, Loss: 158.41302490234375\n",
      "Epoch: 92100, Loss: 158.25473022460938\n",
      "Epoch: 92200, Loss: 158.22756958007812\n",
      "Epoch: 92300, Loss: 158.22705078125\n",
      "Epoch: 92400, Loss: 158.2210693359375\n",
      "Epoch: 92500, Loss: 158.225830078125\n",
      "Epoch: 92600, Loss: 158.222412109375\n",
      "Epoch: 92700, Loss: 158.22543334960938\n",
      "Epoch: 92800, Loss: 158.25514221191406\n",
      "Epoch: 92900, Loss: 158.22296142578125\n",
      "Epoch: 93000, Loss: 158.2247314453125\n",
      "Epoch: 93100, Loss: 158.23504638671875\n",
      "Epoch: 93200, Loss: 158.2322540283203\n",
      "Epoch: 93300, Loss: 158.2955780029297\n",
      "Epoch: 93400, Loss: 158.601806640625\n",
      "Epoch: 93500, Loss: 158.463623046875\n",
      "Epoch: 93600, Loss: 157.88034057617188\n",
      "Epoch: 93700, Loss: 157.69992065429688\n",
      "Epoch: 93800, Loss: 157.67698669433594\n",
      "Epoch: 93900, Loss: 157.67210388183594\n",
      "Epoch: 94000, Loss: 157.6710968017578\n",
      "Epoch: 94100, Loss: 157.67916870117188\n",
      "Epoch: 94200, Loss: 157.73263549804688\n",
      "Epoch: 94300, Loss: 157.68600463867188\n",
      "Epoch: 94400, Loss: 157.67074584960938\n",
      "Epoch: 94500, Loss: 157.73272705078125\n",
      "Epoch: 94600, Loss: 157.68118286132812\n",
      "Epoch: 94700, Loss: 157.77835083007812\n",
      "Epoch: 94800, Loss: 158.0169677734375\n",
      "Epoch: 94900, Loss: 157.56834411621094\n",
      "Epoch: 95000, Loss: 157.46856689453125\n",
      "Epoch: 95100, Loss: 158.25918579101562\n",
      "Epoch: 95200, Loss: 157.33335876464844\n",
      "Epoch: 95300, Loss: 157.19802856445312\n",
      "Epoch: 95400, Loss: 157.15823364257812\n",
      "Epoch: 95500, Loss: 157.15586853027344\n",
      "Epoch: 95600, Loss: 157.1507568359375\n",
      "Epoch: 95700, Loss: 157.15106201171875\n",
      "Epoch: 95800, Loss: 157.14739990234375\n",
      "Epoch: 95900, Loss: 157.15283203125\n",
      "Epoch: 96000, Loss: 157.1982421875\n",
      "Epoch: 96100, Loss: 157.22079467773438\n",
      "Epoch: 96200, Loss: 157.62777709960938\n",
      "Epoch: 96300, Loss: 156.8567352294922\n",
      "Epoch: 96400, Loss: 156.81063842773438\n",
      "Epoch: 96500, Loss: 156.79319763183594\n",
      "Epoch: 96600, Loss: 156.790283203125\n",
      "Epoch: 96700, Loss: 156.79978942871094\n",
      "Epoch: 96800, Loss: 156.8940887451172\n",
      "Epoch: 96900, Loss: 156.76205444335938\n",
      "Epoch: 97000, Loss: 156.764892578125\n",
      "Epoch: 97100, Loss: 156.7043914794922\n",
      "Epoch: 97200, Loss: 156.70388793945312\n",
      "Epoch: 97300, Loss: 157.1234893798828\n",
      "Epoch: 97400, Loss: 156.95460510253906\n",
      "Epoch: 97500, Loss: 156.5741729736328\n",
      "Epoch: 97600, Loss: 156.07290649414062\n",
      "Epoch: 97700, Loss: 156.03472900390625\n",
      "Epoch: 97800, Loss: 156.03271484375\n",
      "Epoch: 97900, Loss: 156.03256225585938\n",
      "Epoch: 98000, Loss: 156.0306854248047\n",
      "Epoch: 98100, Loss: 156.03018188476562\n",
      "Epoch: 98200, Loss: 156.03579711914062\n",
      "Epoch: 98300, Loss: 156.0395050048828\n",
      "Epoch: 98400, Loss: 156.04051208496094\n",
      "Epoch: 98500, Loss: 156.0480499267578\n",
      "Epoch: 98600, Loss: 156.0304718017578\n",
      "Epoch: 98700, Loss: 156.03457641601562\n",
      "Epoch: 98800, Loss: 156.04676818847656\n",
      "Epoch: 98900, Loss: 156.2220458984375\n",
      "Epoch: 99000, Loss: 156.02301025390625\n",
      "Epoch: 99100, Loss: 156.10882568359375\n",
      "Epoch: 99200, Loss: 155.81166076660156\n",
      "Epoch: 99300, Loss: 155.71939086914062\n",
      "Epoch: 99400, Loss: 155.71307373046875\n",
      "Epoch: 99500, Loss: 155.73477172851562\n",
      "Epoch: 99600, Loss: 155.7318878173828\n",
      "Epoch: 99700, Loss: 155.76742553710938\n",
      "Epoch: 99800, Loss: 156.10293579101562\n",
      "Epoch: 99900, Loss: 156.22312927246094\n",
      "Epoch: 100000, Loss: 155.79226684570312\n",
      "Epoch: 100100, Loss: 155.77328491210938\n",
      "Epoch: 100200, Loss: 155.41233825683594\n",
      "Epoch: 100300, Loss: 155.14820861816406\n",
      "Epoch: 100400, Loss: 155.01065063476562\n",
      "Epoch: 100500, Loss: 154.9612579345703\n",
      "Epoch: 100600, Loss: 154.96127319335938\n",
      "Epoch: 100700, Loss: 154.96240234375\n",
      "Epoch: 100800, Loss: 154.96774291992188\n",
      "Epoch: 100900, Loss: 154.96731567382812\n",
      "Epoch: 101000, Loss: 154.96621704101562\n",
      "Epoch: 101100, Loss: 154.96739196777344\n",
      "Epoch: 101200, Loss: 154.96395874023438\n",
      "Epoch: 101300, Loss: 154.96353149414062\n",
      "Epoch: 101400, Loss: 154.9695587158203\n",
      "Epoch: 101500, Loss: 154.97427368164062\n",
      "Epoch: 101600, Loss: 155.22633361816406\n",
      "Epoch: 101700, Loss: 155.1162109375\n",
      "Epoch: 101800, Loss: 155.27639770507812\n",
      "Epoch: 101900, Loss: 154.73316955566406\n",
      "Epoch: 102000, Loss: 154.56976318359375\n",
      "Epoch: 102100, Loss: 154.6234893798828\n",
      "Epoch: 102200, Loss: 154.51499938964844\n",
      "Epoch: 102300, Loss: 155.22096252441406\n",
      "Epoch: 102400, Loss: 154.2996826171875\n",
      "Epoch: 102500, Loss: 154.28860473632812\n",
      "Epoch: 102600, Loss: 154.2845916748047\n",
      "Epoch: 102700, Loss: 154.27857971191406\n",
      "Epoch: 102800, Loss: 154.31417846679688\n",
      "Epoch: 102900, Loss: 154.30853271484375\n",
      "Epoch: 103000, Loss: 154.29464721679688\n",
      "Epoch: 103100, Loss: 154.29757690429688\n",
      "Epoch: 103200, Loss: 154.46900939941406\n",
      "Epoch: 103300, Loss: 154.40701293945312\n",
      "Epoch: 103400, Loss: 156.34765625\n",
      "Epoch: 103500, Loss: 153.97930908203125\n",
      "Epoch: 103600, Loss: 153.79620361328125\n",
      "Epoch: 103700, Loss: 153.79354858398438\n",
      "Epoch: 103800, Loss: 153.79644775390625\n",
      "Epoch: 103900, Loss: 153.79437255859375\n",
      "Epoch: 104000, Loss: 153.79916381835938\n",
      "Epoch: 104100, Loss: 153.8089599609375\n",
      "Epoch: 104200, Loss: 154.0065460205078\n",
      "Epoch: 104300, Loss: 154.08480834960938\n",
      "Epoch: 104400, Loss: 153.70526123046875\n",
      "Epoch: 104500, Loss: 153.83029174804688\n",
      "Epoch: 104600, Loss: 153.72918701171875\n",
      "Epoch: 104700, Loss: 153.70632934570312\n",
      "Epoch: 104800, Loss: 153.68328857421875\n",
      "Epoch: 104900, Loss: 153.69284057617188\n",
      "Epoch: 105000, Loss: 153.7744140625\n",
      "Epoch: 105100, Loss: 153.932861328125\n",
      "Epoch: 105200, Loss: 153.56686401367188\n",
      "Epoch: 105300, Loss: 153.35353088378906\n",
      "Epoch: 105400, Loss: 153.3119354248047\n",
      "Epoch: 105500, Loss: 153.32562255859375\n",
      "Epoch: 105600, Loss: 153.310302734375\n",
      "Epoch: 105700, Loss: 153.30686950683594\n",
      "Epoch: 105800, Loss: 153.32118225097656\n",
      "Epoch: 105900, Loss: 153.35475158691406\n",
      "Epoch: 106000, Loss: 153.3662109375\n",
      "Epoch: 106100, Loss: 153.36904907226562\n",
      "Epoch: 106200, Loss: 153.4624481201172\n",
      "Epoch: 106300, Loss: 153.30084228515625\n",
      "Epoch: 106400, Loss: 153.43960571289062\n",
      "Epoch: 106500, Loss: 153.4963836669922\n",
      "Epoch: 106600, Loss: 152.85366821289062\n",
      "Epoch: 106700, Loss: 152.681640625\n",
      "Epoch: 106800, Loss: 152.5926513671875\n",
      "Epoch: 106900, Loss: 152.57733154296875\n",
      "Epoch: 107000, Loss: 152.57733154296875\n",
      "Epoch: 107100, Loss: 152.57595825195312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 107200, Loss: 152.57620239257812\n",
      "Epoch: 107300, Loss: 152.5833740234375\n",
      "Epoch: 107400, Loss: 152.5830841064453\n",
      "Epoch: 107500, Loss: 152.59375\n",
      "Epoch: 107600, Loss: 152.5821533203125\n",
      "Epoch: 107700, Loss: 152.66529846191406\n",
      "Epoch: 107800, Loss: 152.60400390625\n",
      "Epoch: 107900, Loss: 152.71514892578125\n",
      "Epoch: 108000, Loss: 152.76187133789062\n",
      "Epoch: 108100, Loss: 153.76644897460938\n",
      "Epoch: 108200, Loss: 152.7173309326172\n",
      "Epoch: 108300, Loss: 152.13092041015625\n",
      "Epoch: 108400, Loss: 152.0367889404297\n",
      "Epoch: 108500, Loss: 151.94668579101562\n",
      "Epoch: 108600, Loss: 151.94183349609375\n",
      "Epoch: 108700, Loss: 151.9503173828125\n",
      "Epoch: 108800, Loss: 151.94387817382812\n",
      "Epoch: 108900, Loss: 151.9451904296875\n",
      "Epoch: 109000, Loss: 151.94085693359375\n",
      "Epoch: 109100, Loss: 151.94064331054688\n",
      "Epoch: 109200, Loss: 151.93899536132812\n",
      "Epoch: 109300, Loss: 151.94808959960938\n",
      "Epoch: 109400, Loss: 151.9752197265625\n",
      "Epoch: 109500, Loss: 152.0291290283203\n",
      "Epoch: 109600, Loss: 151.96197509765625\n",
      "Epoch: 109700, Loss: 151.96731567382812\n",
      "Epoch: 109800, Loss: 152.02749633789062\n",
      "Epoch: 109900, Loss: 151.6449432373047\n",
      "Epoch: 110000, Loss: 151.62586975097656\n",
      "Epoch: 110100, Loss: 151.60899353027344\n",
      "Epoch: 110200, Loss: 151.6095733642578\n",
      "Epoch: 110300, Loss: 151.62428283691406\n",
      "Epoch: 110400, Loss: 151.61651611328125\n",
      "Epoch: 110500, Loss: 151.64683532714844\n",
      "Epoch: 110600, Loss: 151.62184143066406\n",
      "Epoch: 110700, Loss: 151.71084594726562\n",
      "Epoch: 110800, Loss: 151.75411987304688\n",
      "Epoch: 110900, Loss: 151.45457458496094\n",
      "Epoch: 111000, Loss: 151.3957061767578\n",
      "Epoch: 111100, Loss: 151.3025665283203\n",
      "Epoch: 111200, Loss: 151.39071655273438\n",
      "Epoch: 111300, Loss: 151.57537841796875\n",
      "Epoch: 111400, Loss: 151.2667236328125\n",
      "Epoch: 111500, Loss: 151.6944580078125\n",
      "Epoch: 111600, Loss: 151.2967071533203\n",
      "Epoch: 111700, Loss: 151.63232421875\n",
      "Epoch: 111800, Loss: 152.05081176757812\n",
      "Epoch: 111900, Loss: 150.51339721679688\n",
      "Epoch: 112000, Loss: 150.48892211914062\n",
      "Epoch: 112100, Loss: 150.48680114746094\n",
      "Epoch: 112200, Loss: 150.486572265625\n",
      "Epoch: 112300, Loss: 150.48765563964844\n",
      "Epoch: 112400, Loss: 150.49148559570312\n",
      "Epoch: 112500, Loss: 150.48329162597656\n",
      "Epoch: 112600, Loss: 150.48643493652344\n",
      "Epoch: 112700, Loss: 150.48245239257812\n",
      "Epoch: 112800, Loss: 150.48280334472656\n",
      "Epoch: 112900, Loss: 150.485107421875\n",
      "Epoch: 113000, Loss: 150.48538208007812\n",
      "Epoch: 113100, Loss: 150.48764038085938\n",
      "Epoch: 113200, Loss: 150.48939514160156\n",
      "Epoch: 113300, Loss: 150.49954223632812\n",
      "Epoch: 113400, Loss: 150.51893615722656\n",
      "Epoch: 113500, Loss: 150.524658203125\n",
      "Epoch: 113600, Loss: 150.6697235107422\n",
      "Epoch: 113700, Loss: 150.486572265625\n",
      "Epoch: 113800, Loss: 150.30386352539062\n",
      "Epoch: 113900, Loss: 150.78314208984375\n",
      "Epoch: 114000, Loss: 150.20968627929688\n",
      "Epoch: 114100, Loss: 150.12770080566406\n",
      "Epoch: 114200, Loss: 149.93115234375\n",
      "Epoch: 114300, Loss: 149.8993682861328\n",
      "Epoch: 114400, Loss: 149.90113830566406\n",
      "Epoch: 114500, Loss: 149.90887451171875\n",
      "Epoch: 114600, Loss: 150.0179443359375\n",
      "Epoch: 114700, Loss: 149.92098999023438\n",
      "Epoch: 114800, Loss: 149.93011474609375\n",
      "Epoch: 114900, Loss: 151.02731323242188\n",
      "Epoch: 115000, Loss: 149.771240234375\n",
      "Epoch: 115100, Loss: 149.40115356445312\n",
      "Epoch: 115200, Loss: 149.38156127929688\n",
      "Epoch: 115300, Loss: 149.22802734375\n",
      "Epoch: 115400, Loss: 149.22100830078125\n",
      "Epoch: 115500, Loss: 149.21810913085938\n",
      "Epoch: 115600, Loss: 149.21932983398438\n",
      "Epoch: 115700, Loss: 149.22496032714844\n",
      "Epoch: 115800, Loss: 149.2183837890625\n",
      "Epoch: 115900, Loss: 149.22189331054688\n",
      "Epoch: 116000, Loss: 149.2700653076172\n",
      "Epoch: 116100, Loss: 149.23004150390625\n",
      "Epoch: 116200, Loss: 149.32150268554688\n",
      "Epoch: 116300, Loss: 149.37802124023438\n",
      "Epoch: 116400, Loss: 149.687255859375\n",
      "Epoch: 116500, Loss: 149.2040557861328\n",
      "Epoch: 116600, Loss: 148.75112915039062\n",
      "Epoch: 116700, Loss: 148.7139434814453\n",
      "Epoch: 116800, Loss: 148.70501708984375\n",
      "Epoch: 116900, Loss: 148.70513916015625\n",
      "Epoch: 117000, Loss: 148.709228515625\n",
      "Epoch: 117100, Loss: 148.70516967773438\n",
      "Epoch: 117200, Loss: 148.71478271484375\n",
      "Epoch: 117300, Loss: 148.78997802734375\n",
      "Epoch: 117400, Loss: 148.77200317382812\n",
      "Epoch: 117500, Loss: 148.8245391845703\n",
      "Epoch: 117600, Loss: 149.04196166992188\n",
      "Epoch: 117700, Loss: 148.75828552246094\n",
      "Epoch: 117800, Loss: 148.47125244140625\n",
      "Epoch: 117900, Loss: 148.47442626953125\n",
      "Epoch: 118000, Loss: 148.52272033691406\n",
      "Epoch: 118100, Loss: 148.47879028320312\n",
      "Epoch: 118200, Loss: 148.5142364501953\n",
      "Epoch: 118300, Loss: 148.55645751953125\n",
      "Epoch: 118400, Loss: 148.60028076171875\n",
      "Epoch: 118500, Loss: 148.87722778320312\n",
      "Epoch: 118600, Loss: 148.24156188964844\n",
      "Epoch: 118700, Loss: 148.17774963378906\n",
      "Epoch: 118800, Loss: 148.18002319335938\n",
      "Epoch: 118900, Loss: 148.1773681640625\n",
      "Epoch: 119000, Loss: 148.20547485351562\n",
      "Epoch: 119100, Loss: 148.21426391601562\n",
      "Epoch: 119200, Loss: 148.28851318359375\n",
      "Epoch: 119300, Loss: 148.2374725341797\n",
      "Epoch: 119400, Loss: 148.49649047851562\n",
      "Epoch: 119500, Loss: 148.19923400878906\n",
      "Epoch: 119600, Loss: 147.84677124023438\n",
      "Epoch: 119700, Loss: 147.80218505859375\n",
      "Epoch: 119800, Loss: 147.80006408691406\n",
      "Epoch: 119900, Loss: 147.8040313720703\n",
      "Epoch: 120000, Loss: 147.80389404296875\n",
      "Epoch: 120100, Loss: 147.80499267578125\n",
      "Epoch: 120200, Loss: 147.82147216796875\n",
      "Epoch: 120300, Loss: 148.28944396972656\n",
      "Epoch: 120400, Loss: 148.55953979492188\n",
      "Epoch: 120500, Loss: 147.582275390625\n",
      "Epoch: 120600, Loss: 147.54714965820312\n",
      "Epoch: 120700, Loss: 147.539306640625\n",
      "Epoch: 120800, Loss: 147.54441833496094\n",
      "Epoch: 120900, Loss: 147.54946899414062\n",
      "Epoch: 121000, Loss: 147.56631469726562\n",
      "Epoch: 121100, Loss: 147.59234619140625\n",
      "Epoch: 121200, Loss: 147.60272216796875\n",
      "Epoch: 121300, Loss: 147.68887329101562\n",
      "Epoch: 121400, Loss: 147.51019287109375\n",
      "Epoch: 121500, Loss: 147.243896484375\n",
      "Epoch: 121600, Loss: 147.25347900390625\n",
      "Epoch: 121700, Loss: 147.22198486328125\n",
      "Epoch: 121800, Loss: 147.2360076904297\n",
      "Epoch: 121900, Loss: 147.23146057128906\n",
      "Epoch: 122000, Loss: 147.32659912109375\n",
      "Epoch: 122100, Loss: 147.22576904296875\n",
      "Epoch: 122200, Loss: 147.7201385498047\n",
      "Epoch: 122300, Loss: 146.98165893554688\n",
      "Epoch: 122400, Loss: 146.96084594726562\n",
      "Epoch: 122500, Loss: 146.9393768310547\n",
      "Epoch: 122600, Loss: 146.97543334960938\n",
      "Epoch: 122700, Loss: 146.9478302001953\n",
      "Epoch: 122800, Loss: 146.96311950683594\n",
      "Epoch: 122900, Loss: 146.92636108398438\n",
      "Epoch: 123000, Loss: 147.05206298828125\n",
      "Epoch: 123100, Loss: 147.0224151611328\n",
      "Epoch: 123200, Loss: 147.01446533203125\n",
      "Epoch: 123300, Loss: 146.79331970214844\n",
      "Epoch: 123400, Loss: 146.57241821289062\n",
      "Epoch: 123500, Loss: 146.29360961914062\n",
      "Epoch: 123600, Loss: 146.2532196044922\n",
      "Epoch: 123700, Loss: 146.25030517578125\n",
      "Epoch: 123800, Loss: 146.25241088867188\n",
      "Epoch: 123900, Loss: 146.25608825683594\n",
      "Epoch: 124000, Loss: 146.25692749023438\n",
      "Epoch: 124100, Loss: 146.28305053710938\n",
      "Epoch: 124200, Loss: 146.2587890625\n",
      "Epoch: 124300, Loss: 146.257080078125\n",
      "Epoch: 124400, Loss: 146.27978515625\n",
      "Epoch: 124500, Loss: 146.27603149414062\n",
      "Epoch: 124600, Loss: 146.3147430419922\n",
      "Epoch: 124700, Loss: 146.26348876953125\n",
      "Epoch: 124800, Loss: 146.28091430664062\n",
      "Epoch: 124900, Loss: 146.41412353515625\n",
      "Epoch: 125000, Loss: 146.15243530273438\n",
      "Epoch: 125100, Loss: 145.9903564453125\n",
      "Epoch: 125200, Loss: 145.97332763671875\n",
      "Epoch: 125300, Loss: 145.960693359375\n",
      "Epoch: 125400, Loss: 145.95448303222656\n",
      "Epoch: 125500, Loss: 145.95623779296875\n",
      "Epoch: 125600, Loss: 145.9295654296875\n",
      "Epoch: 125700, Loss: 145.99514770507812\n",
      "Epoch: 125800, Loss: 146.21347045898438\n",
      "Epoch: 125900, Loss: 145.97039794921875\n",
      "Epoch: 126000, Loss: 145.42904663085938\n",
      "Epoch: 126100, Loss: 145.3647918701172\n",
      "Epoch: 126200, Loss: 145.37429809570312\n",
      "Epoch: 126300, Loss: 145.37100219726562\n",
      "Epoch: 126400, Loss: 145.36871337890625\n",
      "Epoch: 126500, Loss: 145.36721801757812\n",
      "Epoch: 126600, Loss: 145.3664093017578\n",
      "Epoch: 126700, Loss: 145.36541748046875\n",
      "Epoch: 126800, Loss: 145.36361694335938\n",
      "Epoch: 126900, Loss: 145.373779296875\n",
      "Epoch: 127000, Loss: 145.39382934570312\n",
      "Epoch: 127100, Loss: 145.38650512695312\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000000\n",
    "# Step 13: Train the model\n",
    "print(\"Start training the model...\")\n",
    "loss_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    loss = train_agent(agent, iterator)\n",
    "    loss_list.append(loss.loss)\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: {}, Loss: {}\".format(epoch, loss.loss))\n",
    "\n",
    "print(\"Training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcea61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14: Test the model\n",
    "print(\"Evaluate the model...\")\n",
    "true_labels = []\n",
    "predicted_actions = []\n",
    "time_step = test_env.reset()\n",
    "cumulative_reward = 0\n",
    "while not time_step.is_last():\n",
    "    action_step = agent.policy.action(time_step)\n",
    "    time_step = test_env.step(action_step.action)\n",
    "    cumulative_reward += time_step.reward\n",
    "    true_labels.append(int(time_step.observation[-1][0]))\n",
    "    predicted_actions.append(np.argmax(action_step.action))\n",
    "\n",
    "print(\"Test episode ended with reward: {}\".format(cumulative_reward))\n",
    "\n",
    "# Evaluate the model's performance\n",
    "correct = 0\n",
    "for i in range(len(true_labels)):\n",
    "    if true_labels[i] == predicted_actions[i]:\n",
    "        correct += 1\n",
    "        \n",
    "print(\"Accuracy: {}\".format(correct / len(true_labels)))\n",
    "\n",
    "# Display the comparison between true labels and predicted actions\n",
    "for i in range(len(true_labels)):\n",
    "    print(\"True label: {}, Predicted action: {}\".format(true_labels[i], predicted_actions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bfce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Step 14: Test the model\n",
    "print(\"Evaluate the model...\")\n",
    "true_labels = []\n",
    "predicted_actions = []\n",
    "time_step = test_env.reset()\n",
    "cumulative_reward = 0\n",
    "while not time_step.is_last():\n",
    "    action_step = agent.policy.action(time_step)\n",
    "    time_step = test_env.step(action_step.action)\n",
    "    cumulative_reward += time_step.reward\n",
    "    true_labels.append(int(time_step.observation[:, -1]))\n",
    "    predicted_actions.append(np.argmax(action_step.action[0]))\n",
    "\n",
    "print(\"Test episode ended with reward: {}\".format(cumulative_reward))\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_actions)\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f3faee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predicted_actions)):\n",
    "    print(\"Index: {}\\tPredicted action: {}\".format(i, predicted_actions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf7d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 15: Visualize the loss\n",
    "plt.plot(loss_list)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72b4613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b924c683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae76ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
